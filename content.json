{"meta":{"title":"Questionable Engineering","subtitle":"","description":"A collection of pointless, random, and probaly bad ideas","author":"John Grun","url":"http://questionableengineering.com","root":"/"},"pages":[{"title":"about","date":"2020-09-04T15:30:57.000Z","updated":"2020-09-04T15:30:57.621Z","comments":true,"path":"about/index.html","permalink":"http://questionableengineering.com/about/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-09-04T15:30:38.000Z","updated":"2020-09-04T15:30:38.928Z","comments":true,"path":"tags/index.html","permalink":"http://questionableengineering.com/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2020-09-04T15:28:51.000Z","updated":"2020-09-04T15:28:51.095Z","comments":true,"path":"categories/index.html","permalink":"http://questionableengineering.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Grub Boot Loader Not Found","slug":"Grub-Boot-Loader-Not-Found","date":"2019-12-23T19:41:32.000Z","updated":"2019-12-23T19:55:14.000Z","comments":true,"path":"2019/12/23/Grub-Boot-Loader-Not-Found/","link":"","permalink":"http://questionableengineering.com/2019/12/23/Grub-Boot-Loader-Not-Found/","excerpt":"","text":"Insert Grub console picture here run the following commands ls Will show you all the drive parations (hd0,gpt1) ls (hdo,gpt1)/ Will give you a listing of all the files on the dive Find the drive that contains /boot (hd0,gpt1)/boot locate the grub.cfg configfile /PathToFile/grub.cfg configfile (hd0,gpt1)/boot/grub/grub.cfg Grub boot menu should start. Kernel is now running Fix any broken packagesdpkg –configure -a Check systemctl Look for any errors that may have occured. Fix any filesystem errors that may have occures look in /dev/disk/by-uuid Perform fsck on any drives that require a repair.fsck /dev/disk/by-uuid/abc456 Often the grub loader cannot find the efi file sudo apt install grub-efi-amd64","categories":[],"tags":[{"name":"Fixes","slug":"Fixes","permalink":"http://questionableengineering.com/tags/Fixes/"}]},{"title":"QuadCopterBumbleBee","slug":"QuadCopterBumbleBee","date":"2019-01-20T16:08:15.000Z","updated":"2020-09-04T03:37:12.655Z","comments":true,"path":"2019/01/20/QuadCopterBumbleBee/","link":"","permalink":"http://questionableengineering.com/2019/01/20/QuadCopterBumbleBee/","excerpt":"","text":"BumbleBee Quad CopterFrameBumbleBeeFrame ConfigurationQuad X ControllerReadytosky Pixhawk PX4 Flight Controller Autopilot PIX 2.4.8 32 Bit Flight Control Board+Safety Switch+Buzzer+I2C Splitter Expand Module+16GB SD Card NavigationReadytosky M8N GPS Module Built-in Compass Protective Case with GPS Antenna Mount for Standard Pixhawk 2.4.6 2.4.8 Flight Controller Remote ControlTurnigy TGY-I6PWM To PPM Conversionusmile PPM Encoder With 10pin Input &amp; 4pin Output Cable For Pixhawk/PPZ/MK/MWC/Pirate Flight Control Motor ControllersTurnigy MultiStar V.20Internal BEC provides 5V to the rest of the systemWARNING: If using ESC BECs to power your system you may need to disconnect all but one of the 5 volt connections from the ESC BEC. Only 1 power source! Power3300 mAH Battery SoftwareFirmwareArdupilothttp://ardupilot.org/ Mission Planner ( Ground Control )APM Planner V2.0http://ardupilot.org/planner2/ PicturesFrameTesting Motor ConnectionsFront Left Front Right Rear Left Rear Right","categories":[],"tags":[]},{"title":"React_Native_Watch_Limit_Fix","slug":"React-Native-Watch-Limit-Fix","date":"2017-12-31T00:02:42.000Z","updated":"2017-12-31T00:08:59.000Z","comments":true,"path":"2017/12/30/React-Native-Watch-Limit-Fix/","link":"","permalink":"http://questionableengineering.com/2017/12/30/React-Native-Watch-Limit-Fix/","excerpt":"","text":"Ubuntu Watch filesystem limit Work AroundIn the terminal run sudo gedit /etc/sysctl.conf fs.inotify.max_user_instances=524288 fs.inotify.max_user_watches=524288 fs.inotify.max_queued_events=524288 Reboot for changes to take effect.","categories":[],"tags":[{"name":"Fixes","slug":"Fixes","permalink":"http://questionableengineering.com/tags/Fixes/"},{"name":"React Native","slug":"React-Native","permalink":"http://questionableengineering.com/tags/React-Native/"}]},{"title":"Electrical_Enclosures_With_OpenScad","slug":"Electrical-Enclosures-With-OpenScad","date":"2017-12-30T18:38:54.000Z","updated":"2020-09-04T03:38:43.975Z","comments":true,"path":"2017/12/30/Electrical-Enclosures-With-OpenScad/","link":"","permalink":"http://questionableengineering.com/2017/12/30/Electrical-Enclosures-With-OpenScad/","excerpt":"Using open scad to produce backplates for electrical enclosuresI needed a backplate for an electrical enclosure. Instead of waiting a few days I decided to 3d print one. Figure 1: NEMA4X Electrical Enclosure","text":"Using open scad to produce backplates for electrical enclosuresI needed a backplate for an electrical enclosure. Instead of waiting a few days I decided to 3d print one. Figure 1: NEMA4X Electrical Enclosure Tools: * Micrometer * Calculator * OpenScad * Cura OpenScad code: echo(version=version()); difference() &#123; color(&quot;red&quot;) translate([0, -0, 0]) linear_extrude(height = 2) square([121, 121], center = true); translate([-60.5,-60.5,0]) linear_extrude(height = 2) square([30,30], center = true); translate([60.5,-60.5,0]) linear_extrude(height = 2) square([30,30], center = true); translate([60.5,60.5,0]) linear_extrude(height = 2) square([30,30], center = true); translate([-60.5,60.5,0]) linear_extrude(height = 2) square([30,30], center = true); &#125; Figure 2: OpenScad Figure 3: Cura","categories":[],"tags":[{"name":"OpenScad","slug":"OpenScad","permalink":"http://questionableengineering.com/tags/OpenScad/"},{"name":"Electrical","slug":"Electrical","permalink":"http://questionableengineering.com/tags/Electrical/"},{"name":"Mechanical","slug":"Mechanical","permalink":"http://questionableengineering.com/tags/Mechanical/"}]},{"title":"Hexo Asset Posts Work Around","slug":"Hexo-Asset-Posts-Work-Around","date":"2017-12-27T01:15:57.000Z","updated":"2020-09-04T03:39:01.567Z","comments":true,"path":"2017/12/26/Hexo-Asset-Posts-Work-Around/","link":"","permalink":"http://questionableengineering.com/2017/12/26/Hexo-Asset-Posts-Work-Around/","excerpt":"Even thou Hexo suports markdown, the current asset folders implmention is hacky at best.It does not allow for additional fields. Without the asset_path or image tag your image will often not show up on the index page.The following code will allow you to set properties and display the image on the index page &lt;img src=&quot;&#123;% asset_path image_0.png %&#125;&quot; style=&quot;width: 90%;&quot;/&gt; A better way would be to include the markdown file in the Asset Folder.","text":"Even thou Hexo suports markdown, the current asset folders implmention is hacky at best.It does not allow for additional fields. Without the asset_path or image tag your image will often not show up on the index page.The following code will allow you to set properties and display the image on the index page &lt;img src=&quot;&#123;% asset_path image_0.png %&#125;&quot; style=&quot;width: 90%;&quot;/&gt; A better way would be to include the markdown file in the Asset Folder.","categories":[],"tags":[{"name":"Fixes","slug":"Fixes","permalink":"http://questionableengineering.com/tags/Fixes/"},{"name":"Hexo","slug":"Hexo","permalink":"http://questionableengineering.com/tags/Hexo/"}]},{"title":"Investigation of Memory Dependence Strategies","slug":"Investigation-of-Memory-Dependence-Strategies","date":"2017-09-16T01:43:08.000Z","updated":"2020-09-04T03:40:48.524Z","comments":true,"path":"2017/09/15/Investigation-of-Memory-Dependence-Strategies/","link":"","permalink":"http://questionableengineering.com/2017/09/15/Investigation-of-Memory-Dependence-Strategies/","excerpt":"Computer ArchitectureInvestigation of Memory Dependence Prediction Strategies with SimpleScalarLorenzo Allas, John Grun, Sanandeesh Kamat 0.0 AbstractA dynamically scheduled processor may default to in-order execution of Load/Store instructions to avoid Memory Order Violations. This is because, loads executed out of order may be dependent upon prior stores, the addresses of which were initially unknown. To overcome the potentially wasted clock cycles of conservatively stalled loads, known as False Dependencies, Memory Dependence Predictor (MDP) schemes have been developed. This paper demonstrates the implementation of two experimental MDP schemes, Store Sets and Counting Dependence Predictor (CDP) within the SimpleScalar framework. In addition, it demonstrates two baseline MDP schemes, No Speculation and Naive Speculation. The conceptual overview, the software implementation details, as well as quantitative simulation results are provided. The performance of these MDP schemes has been evaluated in terms of three metrics: the number of Memory Order Violations, the number of False Dependencies, and the average IPC. Although the results did not indicate a performance enhancement in terms of execution time, they do demonstrate expected behavior in terms of Memory Order Violations and False Dependencies. Possible implementation shortcomings, and future alterations are later proposed.","text":"Computer ArchitectureInvestigation of Memory Dependence Prediction Strategies with SimpleScalarLorenzo Allas, John Grun, Sanandeesh Kamat 0.0 AbstractA dynamically scheduled processor may default to in-order execution of Load/Store instructions to avoid Memory Order Violations. This is because, loads executed out of order may be dependent upon prior stores, the addresses of which were initially unknown. To overcome the potentially wasted clock cycles of conservatively stalled loads, known as False Dependencies, Memory Dependence Predictor (MDP) schemes have been developed. This paper demonstrates the implementation of two experimental MDP schemes, Store Sets and Counting Dependence Predictor (CDP) within the SimpleScalar framework. In addition, it demonstrates two baseline MDP schemes, No Speculation and Naive Speculation. The conceptual overview, the software implementation details, as well as quantitative simulation results are provided. The performance of these MDP schemes has been evaluated in terms of three metrics: the number of Memory Order Violations, the number of False Dependencies, and the average IPC. Although the results did not indicate a performance enhancement in terms of execution time, they do demonstrate expected behavior in terms of Memory Order Violations and False Dependencies. Possible implementation shortcomings, and future alterations are later proposed. 1.0 Introduction1.1 The Question: To Issue Load or not to Issue Load?In a pipelined In-Order execution processor, if an instruction is dependent upon the result of a previously issued instruction then entire processor pipeline must be stalled. This has the effect of drastically reducing the throughput of the processor by, stalling later instructions that have no dependence upon the stalling instruction. To circumvent the performance limitations inherent in the In-Order pipelined processor designs, dynamic scheduling (Out of Order execution) was introduced. Dynamic scheduling works by allowing instructions to issue out of order. Thus if an instruction is issued and is dependent upon the result of a previous instruction, later instructions do not need to wait. Later non-dependent instructions are allowed to issue as long as the processor has available resources (e.g. Adder, Multiplier, FPU, etc.). Inconveniently, the target memory addresses of memory access instructions (i.e. load/store) are not resolved until after issue. Therefore, earlier implementations of dynamic scheduling (e.g.Tomasulo) issued loads and stores in program order to prevent memory order violations. Memory Order Violations occur when loads and store operate on the same memory address in the incorrect order and thus produce incorrect program execution. While this method ensured the correct program execution, the benefits of dynamic scheduling were not realized for load and store instructions. Additionally, any instructions that are dependent have to wait for the Load or store operation to complete even if disperse loads and stores do not operate on the same memory address. In order to maximize performance gains, researchers began experimenting with schemes to allow for out of order execution of loads and stores. In this paper we shall evaluate two such schemes: Store Sets, and Counting Dependency Predictors. 1.2 The Answer: Memory Dependence Prediction SchemesWhen issuing a load out of program order, it is assumed that the load does not share an address with (i.e. depend upon) any stores which it has overtaken. Therefore, to issue loads out of program order while target addresses are unavailable, the processor requires Memory Dependence Prediction (MDP). This is very similar to Branch Prediction in that the processor guesses on a decision, detects a mishap, recovers state, and learns to avoid the same mistake on future encounters. The two baseline (i.e. corner-cases) MPD schemes are No Speculation and Naive Speculation. Under the terms of No Speculation, no ready loads will queue unless there are no non-ready stores behind it. Under the terms of Naive Speculation, loads will queue as soon as they are ready regardless of the number of non-ready loads behind it. Figure 2 illustrates the concepts of these two schemes. No Speculation and Naive Speculation represent the most conservative and the most aggressive MDP schemes, respectively. Under the terms of the Store Sets algorithms, the processor incrementally logs the PCs of stores upon which loads have historically depended to determine the earliest point in time at which a given load may issue. As conflicting stores are first encountered (detected by Memory Order Violations), their PCs are added to the Store Set to improve future performance. Figure 3 shows illustrates this concept. Today, distributed systems within which centralized fetch and execution streams are infeasible pose a complication for MDP schemes such as Store Sets. To accommodate distributed systems for which memory dependence predictors do not have global knowledge stores at the full program level, the Counting Dependence Predictor (CDP) scheme predicts the number of stores (not specific PCs) which a load must wait for before it is issued. Moreover, the CDP can default the behavior of a given load to No Speculation (conservative) or Naive Speculation (aggressive) depending on how well it performs at run time. A state machine shown in Figure 4 prescribes the behavior of a given load and is designed to maximize overall performance without requisite maintenance of global store information. 1.3 The Purpose of this ProjectThe purpose of this project was to extend the SimpleScalar’s sim-outorder simulator to investigate the effectiveness of Store Sets and CDP as MDP schemes. This required familiarization with the SimpleScalar/sim-outorder source code as well as with the selected MDP schemes. Practical feasibility (e.g. memory/power economy) was not a concern of this simulation-driven project, and so the presented implementations represent idealized behavior with unrestricted architectural resources. 2.0 Methods &amp; Materials2.1 Overview of the SimpleScalar Out-of-Order SimulatorThis project utilized the SimpleScalar Toolset to design/evaluate MDP schemes. The SimpleScalar toolset is divided into modules which are applicable to different types/levels of architectural analysis. Because this project was investigating a type of dynamic scheduling, the sim-outorder module was used. Conveniently, the sim-outorder software is solely confined to the file,simoutorder.c. Sim-outorder centers around the Register-Update-Unit(RUU) and Load-Store-Queue (LSQ) which allow instructions to issue/execute out of order but retire in order. Figure 1 illustrates the pipeline of sim-outorder. The RUU and LSQ are themselves simply arrays of the RUU_Station type, which is container for status information of in-flight instructions. Figure 1: Pipeline for sim-outorder with Memory Dependence Management Highlighted 2.1.1 Memory Dependence Management with Load-Store-Queue RefreshMemory operations are split into two separate instructions: the addition to compute the effective address and the memory operations itself. The Load-Store-Queue Refresh function (lsq_refresh()), indicated in Figure 1, is an array of RUU_Stations of exclusively loads and stores. It’s functionality is to facilitate memory dependence checking and safe issuing of loads (stores are issued in ruu_issue()). Therefore, lsq_refresh() represented the entry point for most of the software developed for this project. In fact, seach MDP scheme implemented in this project is represented entirely by a variant of lsq_refresh() which is selectively called in it’s stead (See Section 2.3 for details). By default,lsq_refresh() stalls any ready load if there exists an earlier store with an unresolved address in the LSQ. If however, the address is ready but the operands are not, lsq_refresh() will track the the store’s effective address and stall any ready load only if their addresses match. As will be shown next, this is a relaxed form of No Speculation combined with a rudimentary form of memory dependence checking which Store Sets extends across multiple clock cycles. 2.2 Overview of the Performance MetricsThe three metrics by which an MDP scheme is evaluated are (1) the Number of Memory Violations, the (2) Number of False Dependencies which have occurred during a program’s execution and the average (3) Instructions Per Cycle. Memory Order Violation program error in which an out-of-order load loads a value before a prior store with a matching effective address completes storing its value to that address. This requires flushing the pipeline and recovering the processor to the state at the point of the offending load. False Dependency program slow-down in which a ready load is stalled due to the detection of a prior unready store which does not have a matching effective address. This results in wasted clock cycles which reduces program execution speed. Instructions Per Cycle (IPC) The average number of instructions which are retired per cycle. In multiple-issue processors like SimpleScalar, this can easily rise above 1. 2.3 Implementation of the MDP Schemes and Metrics AcquisitionImplementing the MDP schemes primarily involved altering the actions taken during lsq_refresh(). Specifically, what to do in the event of a detected unready store and ready load. By default, simoutorder does not risk the possibility of Memory Order Violations. Moreover, the functionality to track the number of False Dependencies did not exist. Therefore, this project also involved developing code detect/track the events of Memory Order Violations and False Dependencies, which can be found in check_mem_violation() and countNumFalseDependencies(), respectively. Figure 2 : Logic for Memory Dependence Algorithms MDP Scheme Memory Order Violations False Dependencies Project Function Name CLI Default None Many lsq_refresh() 0 No Speculation None Many lsq_refresh_NoSpeculation() 1 Naive Speculation Many None lsq_refresh_NaiveSpeculation() 2 Store Sets Few Few lsq_refresh_InfStoreSets() 3 CDP Few Few lsq_refresh_CountingDependencePredictor() 4 Table 1: Expected relative behavior of algorithms 2.3.1 No Speculation (Conservative)For an algorithm which performs no speculation, the load instructions are dispatched to the memory system only when the addresses of all previous stores are known and the operands of those stores are ready. This configuration successfully avoids memory dependence violations entirely by ensuring memory instructions are issued in program order, but provides no prevention against false memory dependencies (see Table 1). As such, this conservative algorithm served as the baseline memory dependence management scheme against which subsequently implemented prediction schemes were compared for maximum false dependencies. 2.3.2 Naive Speculation (Aggressive)The naive prediction algorithm assumes no memory dependencies among store/load instructions. All load and store instructions are issued as soon as possible. This configuration is the opposite of no speculation in that no false dependencies occur, but maximum amount of memory violations are incurred. As such, this aggressive algorithm served as the baseline MDP scheme against which subsequently implemented MDP schemes were compared for maximum memory violations. Functionality to flush the pipeline when a memory violation occurs was not implemented in this simulation due to time constraints. ###2.3.3 Infinite Store SetsThe Store Sets algorithm predicts future memory violations based on their previous occurrences. Each load is initialized to behave according to Naive Speculation, in that it assumes it can issue as soon as it is able to. Upon detection of a memory order violation, the conflicted store and load relationship is saved into a table for future reference. This table is known as a Store Set. During a queue refresh, each ready load’s Store Set is searched for a match (i.e. conflict) with any unready store currently behind it. If a conflict is found, the load is stalled until the matching store is no longer on the LSQ. Because no limits are imposed upon (1) the number of stores a load’s store set can contain, or (2) the number of store sets within which a unique store PC can exist, this implementation is considered to be an Infinite Store Set. These limits do exist in practical implementations which were not considered in this project. Figure 2 illustrates the simplified Infinite Store Sets concept implemented in this project. For the project implementation, the Store Set Index is a C struct and the Store Set itself is simply a C array of addresses. Figure 3: Infinite Store Sets 2.3.4 Counting Dependence PredictionThe counting dependence prediction algorithm uses a state machine for each unique load to determine the correct course of action. Unlike the Store Sets algorithm, the CDP algorithm does not maintain a record of specific Store PCs. Rather, it logs the number of stores which a load must wait for after being ready. This layer of detachment makes CDP an attractive MDP scheme for distributed systems within which globally broadcasted information may not be feasible.Similar to the store set algorithm, each load is initialized to behave according to Naive Speculation (i.e.Aggressive 00 ). As soon as a Memory Order Violation is detected, the state changes to No Speculation (i.e. Conservative. Figure 4: Counting Dependence Predictor State Machine Diagram As long as there is determined to be &gt;1 prior stores upon which this load depends (i.e. a Match ), the load will remain Conservative. As soon as there is determined to be 0 or 1 matching stores, the state will change to One-Store and volley between 01 or 11, respectively. If at any time, however, a Memory Order Violation is detected, the load’s CDP state will return to Conservative. Figure 2 illustrates the CDP concept implemented in this project. For the project implementation, CDP Index is a C struct and the CDP state itself is simply a C enum comprising of the four aforementioned states. 2.3.5 Memory Order Violation and False Dependency DetectionBecause both Store Sets and CDP are initialized/updated by the event of Memory Order Violations, the project’s check_mem_violation() served three simultaneous purposes. Flags Memory Order Violations: issued loads the address of which conflicts with an unexecuted store(s). Initializes/Updates the Store Set of the Offending Load Initializes/Updates the CDP of the Offending Load Therefore, although check_mem_violation() is ostensibly merely metric tracker, it also completes the implementation of Store Set and CDP with state feedback The algorithm for Memory Order Violation detection is shown in Figure 5. What allows this algorithm to be effective is that it is called within RUU_Issue() specifically when a ready load is about to be executed. The False Dependency detection function ( countNumFalseDependencies() ), however, is purely a metric tracker and does not alter the state of ongoing Store Sets or CDP state structures. It is called immediately after the LSQ is refreshed. As shown in Figure 5, it simply counts the number of ready loads which come after an unready store. This is a definition of False Dependency which applies closely to No Speculation, but is loosely applicable to the other MDP schemes. Figure 5: Logic for Memory order Violation Check and False Dependency Check 2.4 Implementation of the SimulationsThe following test programs were run using the aforementioned MDP schemes. Test Programs anagram test-args test-dirent test-fmath test-llong test-lswlr test-printf Table 2: Test programs used in the experiment SimpleScalar Parameter Val Instruction Fetch Queue Size (in inst/s) 4 Instruction Decode Width (insts/cycle) 4 Instruction Issue B/W (insts/cycle) 4 Instruction Commit B/W (insts/cycle) 4 Memory Access Bus Width (in bytes) 8 Register Update Unit Size 8 Load/Store Queue Size 4 Table 3: Relevant Default Parameters for the Simulations In order to specify the MDP scheme to run, additional code was written to selectively invoke a different lsq_reshresh_*() depending on the command line arguments as follows: ./sim-outorder - ALGORITHM_TYPE 0 ./tests/bin/* // 0. Default SimpleScalar Behavior ./sim-outorder -ALGORITHM_TYPE 1 ./tests/bin/* // 1. No Speculation ./sim-outorder -ALGORITHM_TYPE 2 ./tests/bin/* // 2. Naive Speculation ./sim-outorder -ALGORITHM_TYPE 3 ./tests/bin/* // 3. Store Sets ./sim-outorder -ALGORITHM_TYPE 4 ./tests/bin/* // 4. Counting Dependence Predictor By invoking the -redir:sim command line argument simulation outputs were automatically logged to text files. These text files were generated for every combination of test program and MDP scheme, including Default. This resulted in different simulation output text files each of which contain the three principal performance metrics: Number of Memory Violations, Number of False Dependencies, and Average IPC. These results are shown in the next section. 3.0 Results3.1 Instructions Per Cycle (IPC)The IPC is most direct measure of overall program performance. According to Figure 6, the various MDP schemes applied to the test data did not result in significant variation in IPC. Because the simulation parameters were fixed solely as described in Table 3, it is possible that these results would have shown greater variance if B/Ws were increased. Nonetheless, there was a consistent decrease in IPC for No Speculation which is by definition the most sluggish of all MDP schemes. MDP Scheme \\ Program args dirent fmath llong lswlr Math printf Default 0.4638 0.3924 0.7803 0.6043 0.3613 0.9452 1.4645 No Spec 0.4635 0.3923 0.7778 0.6030 0.3611 0.9410 1.4531 Naive Spec 0.4641 0.3924 0.7803 0.6046 0.3613 0.9454 1.4658 Store Sets 0.4641 0.3924 0.7803 0.6045 0.3613 0.9453 1.4645 CDP 0.4610 0.3886 0.7773 0.3701 0.3588 0.8011 0.5214 Table 4: Raw IPC Across Test Programs and MDP Schemes Figure 6: Plotted IPC Across Test Programs and MDP Schemes 3.2 Number of Memory Order ViolationsThe number of Memory Order Violations generated by the simulations was largely consistent with the initial hypothesis. This is in that the Default, and No Speculation MDP schemes consistently resulted in zero Memory Order Violations. This verifies the project’s implementation of the check_mem_violation() function. By design, the Store Sets and CDP algorithm are intended to incur a few number of Memory Order Violations while affording an enhanced IPC. Because the results of the previous section indicated no IPC enhancements, sadly, we merely have only the predicted Memory Order Violation incursion. MDP Scheme \\ Program args dirent fmath llong lswlr Math printf Default 0 0 0 0 0 0 0 No Spec 0 0 0 0 0 0 0 Naive Spec 3 0 5 15 0 45 1745 Store Sets 3 0 5 6 0 17 26 CDP 2 0 4 2 0 8 3 Table 5 : Memory Violation Count Across Test Programs and MDP Schemes Figure 7: Plotted Memory Violation Count Across Test Programs and MDP Schemes 3.2 Number of False DependenciesThe number of False Dependencies generated by the simulations was also largely consistent with the initial hypothesis. This is in that the Naive Speculation consistently resulted in zero False Dependencies. In addition the No Speculation MDP scheme resulted in the largest number of False Dependencies. This verifies the project’s implementation of the countNumFalseDependencies() function as well as baseline MDP schemes. It is optimistic that the Store Sets and CDP schemes resulted in fewer False Dependencies than the Default and No Speculation. However, as there was no significant improvement in IPC, the overall value of these experimental MDP schemes is still undemonstrated. MDP Scheme \\ Program args dirent fmath llong lswlr Math printf Default 3 0 88 55 0 158 3342 No Spec 436 261 1300 565 351 2124 35342 Naive Spec 0 0 0 0 0 0 0 Store Sets 0 0 3 17 0 52 3591 CDP 17 24 57 22 27 63 27 Table 6: False Dependency Count Across Test Programs and MDP Schemes Figure 8: Plotted False Dependency Count Across Test Programs and MDP Schemes 4.0 DiscussionThe most significant metric which justifies an algorithm’s utility is the IPC. Because these results did not demonstrate a significant enhancement of IPC for either of the two experimental MDP schemes (Store Sets and CDP), their implementations cannot be proclaimed entirely successful. However, there were several aspects of the results which did support the correctness of their implementations and their consistency with theory. For example: As expected, the Default and No Speculation MDPs generated no Memory Order Violations and the Naive Speculation MDP many Memory Order Violations. As expected, the Default and No Speculation MDPs generated significant number of False Dependencies and the Naive Speculation MDP generated no False Dependencies. These facts verify the implementations of the baseline MDPs. For the experimental MDPs, as expected, the Store Sets and CDP did generate Memory Order Violations, which is the trigger event by which the Store Sets and CDPs are to be initialized in the first place. Furthermore, as expected, number of False Dependencies generated by Store Sets and CDP are fewer than those of Default, No Speculation, and Naive Speculation. The various parameters which dictate the width of instructions queueing/decoding/issuing/committing etc. were fixed for all simulations at either 4 or 8 (See Table 3). Because MDP schemes are intended to yield greater dividends for higher bandwidth processors, it is possible that increasing these parameters would reveal inter-MDP scheme variation in IPC. A follow on study in which the parameters of Table 3 are modulated could demonstrate this. Nonetheless there are a few implementation features of Store Sets, CDP, and metric tracking which were either approximated here or entirely foregone. For example, although the mechanism to detect Memory Order Violations was implemented, the mechanism to recover processor state to the point of the offending load was not. This mechanism would be entirely analogous to that of processor state recovery during branch mis-prediction. The reason no such MDP recovery mechanism existed at first is that the default implementation of SimpleScalar does not allow the possibility of Memory Order Violations at all (See Figure 1). What this should mean is that every Memory Order Violation encountered here caused a programmatic error. However, sim-outorder prints the expected output of each simulated program adjacent to the generated output. Throughout all 40 simulation runs, no differences were seen between the expected and generated outputs. Although the reason for this lack of discrepancy is unknown, it does raise the possibility that SimpleScalar was somehow detecting the Memory Order Violations and recovering processor state. If this is so, the additional clock cycles cost from recovery were already accounted for in the provided results. If not, the implementations provided here are certainly incomplete and represent optimistic IPCs in that the penalty clock cycles of MDP recovery were not accounted for. One last consideration is that the provided implementations did not strive for minimal memory usage in anyway. For instance, the Store Sets and CDP here maintained a separate index for each load. In practice, much like with branch prediction, the CDP and Store Sets would use reduced table sizes for loads to hash into, and not necessarily track all loads across the entire program execution. 5.0 ConclusionBecause the effective addresses of Loads and Stores cannot always be known at the issue stage, dynamic scheduling processors have traditionally defaulted them to in-order scheduling to avoid Memory Order Violations. To exploit more ILP and reduce False Dependencies, Memory Dependence Prediction (MDP) schemes have been developed. This project sought to demonstrate the performance enhancement capabilities of two such MDP schemes, Store Sets and Counting Dependence Predictor (CDP), within the SimpleScalar simulation framework. SimpleScalar is an industry standard simulator and has been independently verified. Carrying out this project required the team’s thorough familiarization with the MDP scheme concepts as well as the SimpleScalar source code. The project’s developed source code was peer reviewed by the members of the group and was submitted for further investigation. The project’s developed source code was submitted with built in functionality to toggle between four different MDP schemes (plus Default); two baseline, and two experimental. The two baseline MDPs, No Speculation and Naive Speculation, successfully demonstrated the predicted behavior of maximizing False Dependencies and Memory Order Violations, respectively. Moreover, the Store Sets and CDP implementations demonstrated an expected moderate incurrence of Memory Order Violations and False Dependencies. However, the Store Sets and CDP did not demonstrate a significant enhancement of IPC; one of the primary benchmarks of an MDP scheme’s utility. Possible explanations for this result include improper input parameter settings detailed in Table 3. Because MDPs are intended for wide-issue processors, it is possible that these particular set of parameters were insufficient to reveal the intended benefits. Moreover, CDP is necessarily a more handicapped version of Store Sets that would only be functionally relevant if SimpleScalar were implemented as a distributed system. This project enabled the group members to not only learn about but take on Computer Architecture research through the power of modelling &amp; simulation. Carrying out this project allowed us to combine architectural theory with hands-on quantitative performance analysis. Doing so allowed us to act in the capacity of, not only students, but designers. 6.0 References[1] G. Z. Chrysos and J. S. Emer. Memory dependence prediction using store sets. In Proceedings of the 25th Annual International Symposium on Computer Architecture, ISCA ‘98, pages 142{153, Washington, DC, USA, 1998. IEEE Computer Society[2] D. Burger, T. M. Austin. The SimpleScalar Tool Set, Version 2.0. [3]F. Roesner, D. Burger, and S. W. Keckler. Counting dependence predictors. In Proceedings of the 35th Annual International Symposium on Computer Architecture ISCA ‘08, pages 215{226, Washington, DC, USA, 2008. IEEE Computer Society.","categories":[],"tags":[{"name":"Research","slug":"Research","permalink":"http://questionableengineering.com/tags/Research/"},{"name":"Computing","slug":"Computing","permalink":"http://questionableengineering.com/tags/Computing/"}]},{"title":"Nodejs 6 on Ubuntu 16.04 LTS","slug":"Nodejs-6-on-Ubuntu-16-04-LTS","date":"2017-09-10T00:52:48.000Z","updated":"2017-12-27T04:17:49.000Z","comments":true,"path":"2017/09/09/Nodejs-6-on-Ubuntu-16-04-LTS/","link":"","permalink":"http://questionableengineering.com/2017/09/09/Nodejs-6-on-Ubuntu-16-04-LTS/","excerpt":"Nodejs 6 on Ubuntu 16.04 LTSERROR : Buffer.alloc is not a function","text":"Nodejs 6 on Ubuntu 16.04 LTSERROR : Buffer.alloc is not a function Fix: upgrade nodejs to Version &gt; 5.1 curl -s https://deb.nodesource.com/gpgkey/nodesource.gpg.key | sudo apt-key add - sudo sh -c &quot;echo deb https://deb.nodesource.com/node_6.x yakkety main \\ &gt; /etc/apt/sources.list.d/nodesource.list&quot; sudo apt-get update sudo apt-get install nodejs","categories":[],"tags":[{"name":"Fixes","slug":"Fixes","permalink":"http://questionableengineering.com/tags/Fixes/"},{"name":"NodeJs","slug":"NodeJs","permalink":"http://questionableengineering.com/tags/NodeJs/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://questionableengineering.com/tags/Ubuntu/"}]},{"title":"Lorawan US connection parameters","slug":"Lorawan-US-connection-parameters","date":"2017-09-09T19:08:24.000Z","updated":"2017-12-27T04:15:36.000Z","comments":true,"path":"2017/09/09/Lorawan-US-connection-parameters/","link":"","permalink":"http://questionableengineering.com/2017/09/09/Lorawan-US-connection-parameters/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Orchids","slug":"Orchids","date":"2017-07-11T02:21:51.000Z","updated":"2017-12-27T04:16:12.000Z","comments":true,"path":"2017/07/10/Orchids/","link":"","permalink":"http://questionableengineering.com/2017/07/10/Orchids/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Analysis of the Kalman Filter Algorithm","slug":"Report","date":"2017-07-07T21:46:15.000Z","updated":"2020-09-04T03:41:08.896Z","comments":true,"path":"2017/07/07/Report/","link":"","permalink":"http://questionableengineering.com/2017/07/07/Report/","excerpt":"**Analysis of the Kalman Filter Algorithm ** MotivationThe Kalman filter finds applications in extracting useful data from inherently noisy sources. One common application is smoothing sensor data. In order for most sensor data to be effectively employed in applications like control loops or navigation systems it must first be filtered in a manner that removes noise but, does not introduce an unacceptable amount of additional error or increases processing and memory load on the system. In this regard the Kalman filter excels. The Kalman filter can also be extended to combine data from multiple input sources to further reduce the error in a signal or sample. This property has many applications in the area of sensor fusion. Kalman filter sensor fusion is commonly used in robotic control systems. A common use case is autonomous vehicle navigation and control eg. Quadcopters or spacecraft. Additionally, the Kalman filter is often used in analog and digital signal processing. The Kalman filter algorithm enjoys implementations in both software and hardware.","text":"**Analysis of the Kalman Filter Algorithm ** MotivationThe Kalman filter finds applications in extracting useful data from inherently noisy sources. One common application is smoothing sensor data. In order for most sensor data to be effectively employed in applications like control loops or navigation systems it must first be filtered in a manner that removes noise but, does not introduce an unacceptable amount of additional error or increases processing and memory load on the system. In this regard the Kalman filter excels. The Kalman filter can also be extended to combine data from multiple input sources to further reduce the error in a signal or sample. This property has many applications in the area of sensor fusion. Kalman filter sensor fusion is commonly used in robotic control systems. A common use case is autonomous vehicle navigation and control eg. Quadcopters or spacecraft. Additionally, the Kalman filter is often used in analog and digital signal processing. The Kalman filter algorithm enjoys implementations in both software and hardware. Describe Algorithm detailsThe Kalman filter algorithm uses multiple input signals samples, often periodically, to increase the overall estimation accuracy of the signal with noise removed. The Kalman filter has 5 sets of variables one must understand. The the first is the self-explanatory unfiltered input signal. It is important to state, the algorithm assumes that all input signals into the filter contain a certain amount of noise variance. The Kalman gain, which is recursively calculated from the variance of the input signal over many samples. The last state (Xk-1) of the system, which is a gain weighted sum of all previous input signal samples. The current state (Xk) , which is an estimate of the expected state of the system as calculated by a function that describes the system/signal. The output signal is a gain weighted sum of the value of the current input signal and the current state estimation of the system. The Kalman filter algorithm uses two main components, a predicative step and a update step. See Figure 1. Figure 1. Simplified process flow representation of input signal and estimation in kalman filter. In the predictive step the Kalman filter relies upon a function model of the system/signal in order to calculate the predicted current state (Xk) from the last state (Xk-1) and any relevant input signals. The system/signal predicted variance is also calculated in this step. In the update step, the next estimated output signal is produced from a gain weighted sum of the estimated current state and the new input signal sample. In the case of a temperature sensor, the Kalman filter would produce a new estimated temperature for the output from the gain weighted sum of previous temperature samples and the new temperature sample. The gain is calculated based upon the variance observed between the predicted variance and the variance of the new sample. The filter is tuned to give a higher weight to samples with lower error. Explain why the chosen algorithms are employed for the problem.The algorithm has found employment as a solution to many common engineering problems such as processing inputs into control systems and for fusing sensor data from multiple sources. The algorithm is popular as a solution to these problems due to its low memory and processing footprint, constant running time, and comparatively simple design as compared to other solutions. The Kalman filter reduces the amount of working memory required by encoding past history of the inputs into a single current state variable (Xk). This encoding reduces the amount of memory consumed by the algorithm as past information does not need to be retained. Additionally, the amount of data processing per signal sample is reduced as only the current state variable and new sample are processed. These reductions in processing and memory are advantages in resource constrained environments, such as embedded systems or hardware implementations. The Kalman filter algorithm also lends itself well to “real time” systems such as robotic control where a predictable delay and constant runtime is required.The Kalman filter algorithm has a O(1) processing complexity and a O(1) memory space complexity. The Kalman filter can also be extended to combine inputs from multiple sources to further reduce signal sample variance. This property lends itself well to applications employing sensor fusion such as inertial navigation units (INUs) Experimental configuration and details.The experiment consists of a force sensitive resistor sensor sampled once every 100 mSec by an Arduino compatible microcontroller(ESP8266). The microcontroller sends the raw sensor samples to the computer over a serial connection. The computer then writes the raw samples to a file on the hard disk (Data.txt). Once a large number of samples have been collected, the raw samples are passed into the Kalman filter(KalmanFilterWrapper.exe). KalmanFilterWrapper.exe produces two output files KALMAN_INPUT_VS_OUTPUT.csv and KALMAN_FILTER_RUNNING_TIME_VS_INPUT_SIZE.csv that contain the raw samples vs the Kalman filtered samples and the running time vs input size respectively. Kalman filters will often have many sensor inputs , process time variant signals, and must account for control inputs. With the addition of more inputs a gain matrix must be maintained that relates each input to each other input in addition to the gain between current Xk and last state Xk-1. These factors quickly drive a simple algorithm into such a complex system that it is used routinely in PHD. thesi. For these reasons, a simple implementation of the Kalman was chosen. Finally, a simpler implementation will clearly show the algorithm operation. The implemented Kalman filter is processing a single variable, static , time invariant signal(Voltage proportional to the weight of Expo marker) In this implementation, the function model of the system/signal is Current state = last state I.e Xk = Xk-n. The test should clearly show noise in raw samples and the resulting filtered output of the Kalman filter. Figure 2: Experimental setup to collect sensor data. EXPO marker used to provide static weight greater than baseline. Figure 3. Schematic of the circuit used to collect data and send information the the computer. Source code and related information to reproduce experiment Arduino code to collect samples: DataStructuresKalmanFilter.ino Schematic of sensor collection: Kalman_sensor_collection_schematic.pdf Kalman filter Source Code see: KalmanFilterWrapper.cpp – Wrapper to process data and produce output files ./KalmanFilter.cpp – Kalman filter implementation Run make in project root to compile C++ source code. make Exec KalmanFilterWrapper.exe to produce outfiles KALMAN_INPUT_VS_OUTPUT.csv KALMAN_FILTER_RUNNING_TIME_VS_INPUT_SIZE.csv All code can be found at https://github.com/JohnGrun/KalmanFilterPaper Sources of Variance in the experimentRaw measurement sources of known varianceThe sensor employed(FSR406) has tolerance of 2% at constant temperature as called out in the data sheet Datasheets_FSR.pdf. At a supply voltage of 3.3v, 2% is ~0.066 Volts of error due to the FSR sensor.See references for link to data sheet. The Esp8266 ADC has a resolution of 12 bits or 4096 divisions. With a Vcc = 3.3V; 4096 = 3.3 Volts, 0 = 0 Volts. A change of 1 in a measurement corresponds to 3.3/4096 = 0.00080566406 Volts. Compared the 0.066 Volts of error introduced by the FSR sensor the ADC resolution is not seen to be significant and, can thus be neglected in calculations. Running time sources of known varianceThe running time of the algorithm may be influenced by external factors such as file system assess, resource allocations, paging, or process scheduling. To compensate for the aforementioned sources of external variances many samples have to be taken. Results and Analysis Figure 4. Sensor samples of proportional voltage to weight of EXPO marker. Raw samples from FSR sensor (Blue). Kalman filtered data of samples (Orange). As can be seen in Figure 4, the raw samples contain a large amount of noise. The standard deviation of the raw samples was 1478.01. A static, time invariant signal( Voltage proportional to the weight of Expo marker) with such a high standard deviation is unusable in real world applications. Once the signal is processed by the Kalman filter, and significant time has passed, the signal become far less variable. The standard deviation of Kalman filtered signal was 98.07, a full order of magnitude less than the raw input signal. Additionally, the filtered signal reached a stable output with low variance as would be expected with a static input signal (Voltage proportional to the weight of Expo marker). Figure 5. Running Time vs Input size. Running time (Blue) of each call to the Kalman filter algorithm using same data in Figure 4. The second graph Figure 5. depicts the running time of the Kalman filter vs the number of samples processed. As expected, the running time is O(1). The Kalman filter only processes one measurement at a time. The output estimation is a weighted sum the past state( all previous samples) and the current measurement state and is updated once per function call. Only for 2 data points out of 5121 samples did the running time change significantly. These 2 data points are likely due to other factors not related to the Kalman filter, such as process scheduling or file system assesses on the host computer. Discussion As can be seen from the results of the experiments the Kalman filter algorithm manages to clean up a noisy signal while running in constant time. There are two limitations of the Kalman filter algorithm. The algorithm requires a finite amount of startup time to reach a output that is representative of the filtered signal see Figure 4. In practice, as long as this startup time can be tolerated, a valid output signal can be extracted. The other limitation is that the Kalman filter algorithm requires knowledge of the process. This is manifested in the prediction stage, where the value of Xk is based upon an equation describing how the system/signal will change over time. E.g. Xk = F(Xkn-1,input1, input2). This makes it difficult to use a Kalman filter algorithm as general case filter, or where the input signal does not have a known function describing its behavior. If one can tolerate these minor shortcomings the Kalman filter algorithm is an excellent choice to clean up noisy input signals with minimal memory and processing overhead. ReferencesThe Extended Kalman Filter: An Interactive Tutorial for Non-Experts. (2017, April 28). Retrieved April 28, 2017, from https://home.wlu.edu/~levys/kalman_tutorial/kalman_01.html Kelly, A. (2006, May 24). A 3D State Space Formulation of a Navigation Kalman Filter for Autonomous Vehicles. Retrieved April 3, 2017, from http://www.frc.ri.cmu.edu/~alonzo/pubs/reports/kalman_V2.pdf Welch, G., &amp; Bishop, G. (2001). An Introduction to the Kalman Filter. Retrieved April 3, 2017, from http://www.cs.unc.edu/~tracker/media/pdf/SIGGRAPH2001_CoursePack_08.pdf Wikipedia. (2017, April 28). Variance. Retrieved April 3, 2017, from https://en.wikipedia.org/wiki/Variance Interlink Electronics. (2017, April 4). FS R ® 400 Series Data Sheet. Retrieved April 4, 2017, from https://www.interlinkelectronics.com/datasheets/Datasheet_FSR.pdf Kohanbash, Y. (2014, January 30). Kalman Filtering – A Practical Implementation Guide (with code!). Retrieved April 29, 2017, from http://robotsforroboticists.com/kalman-filtering/ Wikipedia. (2017, April 06). Kalman filter. Retrieved April 29, 2017, from https://en.wikipedia.org/wiki/Kalman_filter","categories":[],"tags":[{"name":"Kalman","slug":"Kalman","permalink":"http://questionableengineering.com/tags/Kalman/"},{"name":"C++","slug":"C","permalink":"http://questionableengineering.com/tags/C/"},{"name":"Research","slug":"Research","permalink":"http://questionableengineering.com/tags/Research/"}]},{"title":"CNC Conversion MARS","slug":"CNC-Conversion-MARS","date":"2014-10-29T18:49:34.000Z","updated":"2020-09-04T03:32:17.309Z","comments":true,"path":"2014/10/29/CNC-Conversion-MARS/","link":"","permalink":"http://questionableengineering.com/2014/10/29/CNC-Conversion-MARS/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Large CNC","slug":"Large-CNC","date":"2011-12-04T19:40:20.000Z","updated":"2020-09-04T03:42:30.393Z","comments":true,"path":"2011/12/04/Large-CNC/","link":"","permalink":"http://questionableengineering.com/2011/12/04/Large-CNC/","excerpt":"","text":"","categories":[],"tags":[]}],"categories":[],"tags":[{"name":"Fixes","slug":"Fixes","permalink":"http://questionableengineering.com/tags/Fixes/"},{"name":"React Native","slug":"React-Native","permalink":"http://questionableengineering.com/tags/React-Native/"},{"name":"OpenScad","slug":"OpenScad","permalink":"http://questionableengineering.com/tags/OpenScad/"},{"name":"Electrical","slug":"Electrical","permalink":"http://questionableengineering.com/tags/Electrical/"},{"name":"Mechanical","slug":"Mechanical","permalink":"http://questionableengineering.com/tags/Mechanical/"},{"name":"Hexo","slug":"Hexo","permalink":"http://questionableengineering.com/tags/Hexo/"},{"name":"Research","slug":"Research","permalink":"http://questionableengineering.com/tags/Research/"},{"name":"Computing","slug":"Computing","permalink":"http://questionableengineering.com/tags/Computing/"},{"name":"NodeJs","slug":"NodeJs","permalink":"http://questionableengineering.com/tags/NodeJs/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://questionableengineering.com/tags/Ubuntu/"},{"name":"Kalman","slug":"Kalman","permalink":"http://questionableengineering.com/tags/Kalman/"},{"name":"C++","slug":"C","permalink":"http://questionableengineering.com/tags/C/"}]}