<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Questionable Engineering</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://questionableengineering.com/"/>
  <updated>2023-09-03T12:43:01.366Z</updated>
  <id>http://questionableengineering.com/</id>
  
  <author>
    <name>John Grun</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>WLED Degchi Lamp</title>
    <link href="http://questionableengineering.com/2022/08/17/WLED-Degchi-Lamp/"/>
    <id>http://questionableengineering.com/2022/08/17/WLED-Degchi-Lamp/</id>
    <published>2022-08-17T20:16:59.000Z</published>
    <updated>2023-09-03T12:43:01.366Z</updated>
    
    <content type="html"><![CDATA[<p>While traveling in India I came across these nice looking tin lamps. </p><img src="/2022/08/17/WLED-Degchi-Lamp/Degchi_Lamp.jpg" class=""><p>It is sometimes called a Degchi lamp. Since I am not a fan of open flames so leds will have to fill in the role of a candle. This build will be a bit rough. I will refine the lamp in later posts.</p><h1 id="Parts"><a href="#Parts" class="headerlink" title="Parts"></a>Parts</h1><h3 id="Controller"><a href="#Controller" class="headerlink" title="Controller"></a>Controller</h3><h3 id="ESP8266"><a href="#ESP8266" class="headerlink" title="ESP8266"></a>ESP8266</h3><img src="/2022/08/17/WLED-Degchi-Lamp/ESP8266.jpg" class=""><p><a href="https://www.adafruit.com/product/2471">Esp8266 Huzzah</a></p><p><a href="https://learn.adafruit.com/adafruit-huzzah-esp8266-breakout">Esp8266 Huzzah documentation</a></p><h3 id="Level-shifter"><a href="#Level-shifter" class="headerlink" title="Level shifter"></a>Level shifter</h3><img src="/2022/08/17/WLED-Degchi-Lamp/TXS0108E.jpg" class=""><p><a href="https://www.amazon.com/gp/product/B088LMJR5K/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&psc=1">GeeekPi 6Pack TXS0108E 8 Channel Logic Level Converter Bi-Directional High Speed Full Duplex Shifter 3.3V 5V for Arduino Raspberry Pi</a></p><h3 id="LED-Strip"><a href="#LED-Strip" class="headerlink" title="LED Strip"></a>LED Strip</h3><img src="/2022/08/17/WLED-Degchi-Lamp/sk6812.jpg" class=""><p><a href="https://smile.amazon.com/BTF-LIGHTING-Individually-Addressable-Flexible-Non-waterproof/dp/B01N0MA729/ref=sr_1_2?keywords=sk6812+led&qid=1659749420&sr=8-2">Led Strip</a></p><h3 id="Power-supply"><a href="#Power-supply" class="headerlink" title="Power supply"></a>Power supply</h3><img src="/2022/08/17/WLED-Degchi-Lamp/Power_Supply_5V_10A.jpg" class=""><p><a href="https://www.amazon.com/gp/product/B01M0KLECZ/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&psc=1">5v 10 amp power upply with barrel plug</a></p><h3 id="Plug"><a href="#Plug" class="headerlink" title="Plug"></a>Plug</h3><img src="/2022/08/17/WLED-Degchi-Lamp/Barrel_Plug.jpg" class=""><p><a href="https://www.amazon.com/Power-Connector-Female-Adapter-Camera/dp/B07C61434H/ref=sr_1_3?crid=1C8THCD6688TZ&keywords=barrel+plugs&qid=1659770244&sprefix=barel+plugs,aps,92&sr=8-3">Barrel plug</a></p><h1 id="Software"><a href="#Software" class="headerlink" title="Software"></a>Software</h1><h2 id="WLED"><a href="#WLED" class="headerlink" title="WLED"></a>WLED</h2><p><a href="https://github.com/Aircoookie/WLED">wled</a></p><h3 id="Binary"><a href="#Binary" class="headerlink" title="Binary"></a>Binary</h3><p><a href="https://github.com/Aircoookie/WLED/releases/download/v0.13.1/WLED_0.13.1_ESP8266.bin">Wled binary</a></p><h1 id="Flashing"><a href="#Flashing" class="headerlink" title="Flashing"></a>Flashing</h1><p>You will need a 3.3v usb to serial adapter. An FTDI based usb to serial adapteris perfered. </p><p><a href="https://docs.espressif.com/projects/esptool/en/latest/esp32/">https://docs.espressif.com/projects/esptool/en/latest/esp32/</a><br>Method 2 <a href="https://kno.wled.ge/basics/install-binary/">https://kno.wled.ge/basics/install-binary/</a> </p><h2 id="Connections"><a href="#Connections" class="headerlink" title="Connections"></a>Connections</h2><img src="/2022/08/17/WLED-Degchi-Lamp/PXL_20220729_041807877.jpg" class=""><img src="/2022/08/17/WLED-Degchi-Lamp/PXL_20220729_041838804.jpg" class=""><p>Connection between the usb to serial adapter and the ESP8266.</p><ul><li>Logic Level set to 3.3V</li><li>ESP -&gt; FTDI</li><li>TX -&gt; RX</li><li>RX -&gt; TX</li><li>VCC -&gt; 5V</li><li>GND -&gt; GND</li></ul><h2 id="Operating-system-permission-workarounds"><a href="#Operating-system-permission-workarounds" class="headerlink" title="Operating system permission workarounds"></a>Operating system permission workarounds</h2><p>In order to write data to ttyUSB or other serieal ports you must be a member of the dialout group. </p><pre><code>sudo usermod -a -G dialout your_user_nameLog out log in</code></pre><h1 id="Flash-WLED-onto-the-ESP"><a href="#Flash-WLED-onto-the-ESP" class="headerlink" title="Flash WLED onto the ESP"></a>Flash WLED onto the ESP</h1><pre><code>sudo python3 ./esptool.py -p /dev/ttyUSB0 write_flash 0x0 ./WLED_0.13.1_ESP8266.bin</code></pre><h1 id="Electronics"><a href="#Electronics" class="headerlink" title="Electronics"></a>Electronics</h1><h2 id="Schematic"><a href="#Schematic" class="headerlink" title="Schematic"></a>Schematic</h2><img src="/2022/08/17/WLED-Degchi-Lamp/Degchi-Lamp-Electronics.png" class=""><h2 id="Electronics-Rough-Fit"><a href="#Electronics-Rough-Fit" class="headerlink" title="Electronics Rough Fit"></a>Electronics Rough Fit</h2><p>Playing around with the electronics to confirm that the design works as expected.</p><img src="/2022/08/17/WLED-Degchi-Lamp/PXL_20220729_030411413.jpg" class=""><p><br></br></p><img src="/2022/08/17/WLED-Degchi-Lamp/PXL_20220729_030424508.jpg" class=""><p><br></br></p><img src="/2022/08/17/WLED-Degchi-Lamp/PXL_20220729_030434512.jpg" class=""><p><br></br></p><img src="/2022/08/17/WLED-Degchi-Lamp/PXL_20220729_030451769.jpg" class=""><p>Everything is hooked up but the lights are not working. </p><img src="/2022/08/17/WLED-Degchi-Lamp/PXL_20220729_030508542.jpg" class=""><p>Discovered that the OE pin on the TXS0108E needs to be pulled high to VA (ESP Logic Level High 3.3V)</p><img src="/2022/08/17/WLED-Degchi-Lamp/PXL_20220729_041756325.jpg" class=""><img src="/2022/08/17/WLED-Degchi-Lamp/PXL_20220729_212503830.jpg" class=""><h1 id="Physical-Construction"><a href="#Physical-Construction" class="headerlink" title="Physical Construction"></a>Physical Construction</h1><h2 id="Lamp"><a href="#Lamp" class="headerlink" title="Lamp"></a>Lamp</h2><h2 id="Test-Fit"><a href="#Test-Fit" class="headerlink" title="Test Fit"></a>Test Fit</h2><p>Lets see how everything could fit inside the lamp. Who cares how it looks at the moment. We will polish it later. </p><img src="/2022/08/17/WLED-Degchi-Lamp/PXL_20220730_005652066.jpg" class=""><img src="/2022/08/17/WLED-Degchi-Lamp/PXL_20220730_005656922.jpg" class=""><img src="/2022/08/17/WLED-Degchi-Lamp/PXL_20220730_005704671.jpg" class=""><img src="/2022/08/17/WLED-Degchi-Lamp/PXL_20220729_224801450.jpg" class=""><h2 id="Electronics-Enclosure"><a href="#Electronics-Enclosure" class="headerlink" title="Electronics Enclosure"></a>Electronics Enclosure</h2><h3 id="FreeCad-Model"><a href="#FreeCad-Model" class="headerlink" title="FreeCad Model"></a>FreeCad Model</h3><a href="/2022/08/17/WLED-Degchi-Lamp/Degchi_Lamp_Enclosure.FCStd" title="Degchi_Lamp_Enclosure.FCStd">Degchi_Lamp_Enclosure.FCStd</a><img src="/2022/08/17/WLED-Degchi-Lamp/FreeCad.png" class=""><p>First atttempt to create a quick enclosure. </p><img src="/2022/08/17/WLED-Degchi-Lamp/Degchi_Lamp.png" class=""><p>View of the enclosure lid.</p><h3 id="Enclosure-STLs"><a href="#Enclosure-STLs" class="headerlink" title="Enclosure STLs"></a>Enclosure STLs</h3><a href="/2022/08/17/WLED-Degchi-Lamp/Degchi_Lamp_Enclosure-Degchi_Lamp_Electronics_Enclosure.stl" title="Degchi_Lamp_Enclosure-Degchi_Lamp_Electronics_Enclosure.stl">Degchi_Lamp_Enclosure-Degchi_Lamp_Electronics_Enclosure.stl</a><p>Enclosure Main Body</p><a href="/2022/08/17/WLED-Degchi-Lamp/Degchi_Lamp_Enclosure-Degchi_Lamp_Electronics_Cover.stl" title="Degchi_Lamp_Enclosure-Degchi_Lamp_Electronics_Cover.stl">Degchi_Lamp_Enclosure-Degchi_Lamp_Electronics_Cover.stl</a><p>Enclosure Main Body</p><h3 id="Enclosure-Assembly"><a href="#Enclosure-Assembly" class="headerlink" title="Enclosure Assembly"></a>Enclosure Assembly</h3><img src="/2022/08/17/WLED-Degchi-Lamp/PXL_20220809_193334453.jpg" class=""><p>1 amp Fuse</p><img src="/2022/08/17/WLED-Degchi-Lamp/PXL_20220809_193337120.jpg" class=""><p>All the electronics seem to fit. A more professional version will be created when I get the parts.</p><img src="/2022/08/17/WLED-Degchi-Lamp/PXL_20220809_193339631.jpg" class=""><p>Forcing all the electronics into the enclosure.</p><img src="/2022/08/17/WLED-Degchi-Lamp/PXL_20220809_193658141.jpg" class=""><p>Everything is coming together.</p><img src="/2022/08/17/WLED-Degchi-Lamp/PXL_20220809_193854465.jpg" class=""><p>Power on testing</p><h2 id="Led-Mounts"><a href="#Led-Mounts" class="headerlink" title="Led Mounts"></a>Led Mounts</h2><p>The inside of the lamp is coated in a thick non conductive coating. For the time being the led strip is just placed inside the lamp body.</p><h1 id="Connecting-to-WIFI"><a href="#Connecting-to-WIFI" class="headerlink" title="Connecting to WIFI"></a>Connecting to WIFI</h1><p>WLED 13.1 has some trouble connecting to wifi networks. </p><ul><li><p>Set wifi control channel to a fixed channel. e.g 1</p></li><li><p>Change channel width to 20 Mhz</p></li><li><p>Bind to static ip in router</p></li><li><p>Add the same static ip in wled wifi settings </p></li></ul><h1 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h1><img src="/2022/08/17/WLED-Degchi-Lamp/PXL_20220809_195121212.jpg" class=""><p>I am not a fan of this very large black power cable. I will replace the power cord with USB-C.<br>After measuring the power usage of the lamp at peak load it looks like USB-C is a good option. Peak load 0.6 Amps<br>This will be covered in a follow up article. </p><img src="/2022/08/17/WLED-Degchi-Lamp/PXL_20220811_025451240.jpg" class=""><p><br></br></p><img src="/2022/08/17/WLED-Degchi-Lamp/PXL_20220811_025516535.jpg" class=""><p><br></br></p><img src="/2022/08/17/WLED-Degchi-Lamp/PXL_20220811_025517876.jpg" class="">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;While traveling in India I came across these nice looking tin lamps. &lt;/p&gt;
&lt;img src=&quot;/2022/08/17/WLED-Degchi-Lamp/Degchi_Lamp.jpg&quot; class=&quot;
      
    
    </summary>
    
    
      <category term="Electronics" scheme="http://questionableengineering.com/tags/Electronics/"/>
    
      <category term="LED" scheme="http://questionableengineering.com/tags/LED/"/>
    
      <category term="WLED" scheme="http://questionableengineering.com/tags/WLED/"/>
    
      <category term="Hyperion" scheme="http://questionableengineering.com/tags/Hyperion/"/>
    
      <category term="RestAPI" scheme="http://questionableengineering.com/tags/RestAPI/"/>
    
  </entry>
  
  <entry>
    <title>TP Link U3T Ubuntu</title>
    <link href="http://questionableengineering.com/2021/03/11/TP-Link-U3T-Ubuntu/"/>
    <id>http://questionableengineering.com/2021/03/11/TP-Link-U3T-Ubuntu/</id>
    <published>2021-03-11T10:10:00.000Z</published>
    <updated>2022-03-28T23:32:26.245Z</updated>
    
    <content type="html"><![CDATA[<p>This device has the rtl8812bu chipset and you willneed to do a little more work to get it working.<br>Thankfully there is a working driver available for it here: <a href="https://github.com/cilynx/rtl88x2bu">https://github.com/cilynx/rtl88x2bu</a></p><p>To get it working, you will need to first install some packages and check out the Git repo:</p><pre><code>sudo apt-get install build-essential dkms gitgit clone https://github.com/cilynx/rtl88x2bu.git</code></pre><p>Then follow the instructions here to install the driver:</p><pre><code>cd rtl88x2buVER=$(sed -n &#39;s/\PACKAGE_VERSION=&quot;\(.*\)&quot;/\1/p&#39; dkms.conf)sudo rsync -rvhP ./ /usr/src/rtl88x2bu-$&#123;VER&#125;sudo dkms add -m rtl88x2bu -v $&#123;VER&#125;sudo dkms build -m rtl88x2bu -v $&#123;VER&#125;sudo dkms install -m rtl88x2bu -v $&#123;VER&#125;sudo modprobe 88x2bu</code></pre><h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><p><a href="https://askubuntu.com/questions/1230788/ubuntu-20-04-issues-with-tp-link-ac1300-archer-t4u">Ask Ubuntu</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;This device has the rtl8812bu chipset and you willneed to do a little more work to get it working.&lt;br&gt;Thankfully there is a working drive
      
    
    </summary>
    
    
      <category term="Fixes" scheme="http://questionableengineering.com/tags/Fixes/"/>
    
  </entry>
  
  <entry>
    <title>Rigol DS1052E Oscilloscope Encoder Repair</title>
    <link href="http://questionableengineering.com/2020/10/18/Rigol-DS1052E-Oscilloscope-Encoder-Repair/"/>
    <id>http://questionableengineering.com/2020/10/18/Rigol-DS1052E-Oscilloscope-Encoder-Repair/</id>
    <published>2020-10-19T02:42:26.000Z</published>
    <updated>2023-09-02T20:42:55.804Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Broken-encoder"><a href="#Broken-encoder" class="headerlink" title="Broken encoder"></a>Broken encoder</h3><img src="/2020/10/18/Rigol-DS1052E-Oscilloscope-Encoder-Repair/20201006_102529.jpg" class=""><p>I dropped my trusty Rigol scope off of the table while testing. The trigger encoder knob broke off.</p><h3 id="Replacement-part"><a href="#Replacement-part" class="headerlink" title="Replacement part"></a>Replacement part</h3><img src="/2020/10/18/Rigol-DS1052E-Oscilloscope-Encoder-Repair/20201006_105513.jpg" class=""><p>After a bit of googling I was able to locate the part number. This is a very popular scope with hobbyist so this information was not all that hard to find. </p><h3 id="Opening-the-case"><a href="#Opening-the-case" class="headerlink" title="Opening the case"></a>Opening the case</h3><img src="/2020/10/18/Rigol-DS1052E-Oscilloscope-Encoder-Repair/20201006_102830.jpg" class=""><p>The screws that hold the case on are Trox or star drive. There are 6 screws. Two screws on the bottom near the feet, two screws under the handle, and two screws on either side of the power socket.</p><p>WARNING: Do not forget to remove the power button. If you try the case with the power button still in place the switch will snap off. The power button can be removed by pulling it upwards. </p><img src="/2020/10/18/Rigol-DS1052E-Oscilloscope-Encoder-Repair/20201006_103039.jpg" class=""><p>You will need an extension bit to get at the screws under the handle</p><img src="/2020/10/18/Rigol-DS1052E-Oscilloscope-Encoder-Repair/20201006_103144.jpg" class=""><p>Do not forget about the screws on the side</p><img src="/2020/10/18/Rigol-DS1052E-Oscilloscope-Encoder-Repair/20201006_103946.jpg" class=""><p>Back case removed</p><img src="/2020/10/18/Rigol-DS1052E-Oscilloscope-Encoder-Repair/20201006_104202.jpg" class=""><p>Once the case is removed, unscrew the standoffs on either side of the serial interface (DB9).<br>Lift off the metal rf sheild</p><img src="/2020/10/18/Rigol-DS1052E-Oscilloscope-Encoder-Repair/20201006_105641.jpg" class=""><p>You will need to remove all the screws inside of the case. All The power supply board must be removed<br>Disconnect the power supply board. Watch out for the LCD lamp power cable (Red/White cable with JST connector)</p><img src="/2020/10/18/Rigol-DS1052E-Oscilloscope-Encoder-Repair/20201006_105938.jpg" class=""><p>You will need to disconnect the white ribbion cable from the board at the bottom of the unit.</p><p>The front case panel can now be removed. </p><img src="/2020/10/18/Rigol-DS1052E-Oscilloscope-Encoder-Repair/20201006_105555.jpg" class=""><p>Power supply board. Power switch</p><img src="/2020/10/18/Rigol-DS1052E-Oscilloscope-Encoder-Repair/20201006_105710.jpg" class=""><p>Front case panel removed. Picture of the 3 screws holding on the user control board.<br>These will need to be removed.</p><h3 id="Replacing-the-encoder"><a href="#Replacing-the-encoder" class="headerlink" title="Replacing the encoder"></a>Replacing the encoder</h3><img src="/2020/10/18/Rigol-DS1052E-Oscilloscope-Encoder-Repair/20201006_105840.jpg" class=""><p>Boken encoder next to replacement encoder.</p><img src="/2020/10/18/Rigol-DS1052E-Oscilloscope-Encoder-Repair/20201006_110115.jpg" class=""><p>Bottom of the user control board. Unsoldering required.<br>WARNING: Rigol uses lead free solder. Only use lead free solder. If you mix leaded solder and lead free solder a new alloy with a higher melting point will be formed. Good luck removing that!</p><img src="/2020/10/18/Rigol-DS1052E-Oscilloscope-Encoder-Repair/20201006_113918.jpg" class=""><p>Desoldered encoder</p><img src="/2020/10/18/Rigol-DS1052E-Oscilloscope-Encoder-Repair/20201006_113955.jpg" class=""><p>Replacement encoder</p><img src="/2020/10/18/Rigol-DS1052E-Oscilloscope-Encoder-Repair/20201006_121807.jpg" class=""><p>Put everything back together</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Broken-encoder&quot;&gt;&lt;a href=&quot;#Broken-encoder&quot; class=&quot;headerlink&quot; title=&quot;Broken encoder&quot;&gt;&lt;/a&gt;Broken encoder&lt;/h3&gt;&lt;img src=&quot;/2020/10/18/Rig
      
    
    </summary>
    
    
      <category term="Electrical" scheme="http://questionableengineering.com/tags/Electrical/"/>
    
      <category term="Fixes" scheme="http://questionableengineering.com/tags/Fixes/"/>
    
  </entry>
  
  <entry>
    <title>CNC Enclosure Door</title>
    <link href="http://questionableengineering.com/2019/12/26/CNC-Enclosure-Door/"/>
    <id>http://questionableengineering.com/2019/12/26/CNC-Enclosure-Door/</id>
    <published>2019-12-26T23:50:50.000Z</published>
    <updated>2023-09-04T22:45:23.928Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Parts"><a href="#Parts" class="headerlink" title="Parts"></a>Parts</h1><h2 id="Magnetic-Door-Latch"><a href="#Magnetic-Door-Latch" class="headerlink" title="Magnetic Door Latch"></a>Magnetic Door Latch</h2><a href="/2019/12/26/CNC-Enclosure-Door/DoorMagnetLatchMount.scad" title="DoorMagnetLatchMount.scad">DoorMagnetLatchMount.scad</a><a href="/2019/12/26/CNC-Enclosure-Door/DoorMagnetLatchMount.stl" title="DoorMagnetLatchMount.stl">DoorMagnetLatchMount.stl</a><img src="/2019/12/26/CNC-Enclosure-Door/20200110_145308.jpg" class=""><img src="/2019/12/26/CNC-Enclosure-Door/20200110_145251.jpg" class=""><img src="/2019/12/26/CNC-Enclosure-Door/20200110_145254.jpg" class=""><p>3d Printed Magnetic Latch mount</p><img src="/2019/12/26/CNC-Enclosure-Door/20191226_203758.jpg" class=""><h1 id="Mounting-the-Door"><a href="#Mounting-the-Door" class="headerlink" title="Mounting the Door"></a>Mounting the Door</h1><h2 id="Hinges"><a href="#Hinges" class="headerlink" title="Hinges"></a>Hinges</h2><a href="/2019/12/26/CNC-Enclosure-Door/parametric_butt_hinge_3.7.scad" title="parametric_butt_hinge_3.7.scad">parametric_butt_hinge_3.7.scad</a><a href="/2019/12/26/CNC-Enclosure-Door/parametric_butt_hinge_7.stl" title="parametric_butt_hinge_7.stl">parametric_butt_hinge_7.stl</a><p>3d Printed Hinges</p><p>Door temporarily held on by clamps. Hinges mounted to the frame. Using a center locating punch through the hing mounting holes to locate where to drill the hole. </p><img src="/2019/12/26/CNC-Enclosure-Door/20200111_140324.jpg" class=""><img src="/2019/12/26/CNC-Enclosure-Door/20200111_140316.jpg" class=""><img src="/2019/12/26/CNC-Enclosure-Door/20200111_140331.jpg" class=""><p>Determining the correct drilling points with a punch</p><img src="/2019/12/26/CNC-Enclosure-Door/20191226_185050.jpg" class=""><p>Drilling Hinge Mounting Holes.<br>In this case I tapped the acrylic plate with a 1/4-20 tap. These holes need to be kept away from the edge otherwise breakage can occur. Additionally, spreading the load across many holes reduces the stress on any one hole.</p><img src="/2019/12/26/CNC-Enclosure-Door/20200111_150517.jpg" class=""><img src="/2019/12/26/CNC-Enclosure-Door/20200111_150509.jpg" class=""><p>Mounting the door with the hinges<br>Door mounted with the 1/4-20 bolts</p><img src="/2019/12/26/CNC-Enclosure-Door/20200111_150458.jpg" class=""><p>Door Mounted to Hinges</p><h2 id="Door-Handle"><a href="#Door-Handle" class="headerlink" title="Door Handle"></a>Door Handle</h2><a href="/2019/12/26/CNC-Enclosure-Door/ENCLOSURE_HANDLE.zip" title="ENCLOSURE_HANDLE.zip">ENCLOSURE_HANDLE.zip</a><a href="/2019/12/26/CNC-Enclosure-Door/MU_HANDLE.3mf" title="MU_HANDLE.3mf">MU_HANDLE.3mf</a>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Parts&quot;&gt;&lt;a href=&quot;#Parts&quot; class=&quot;headerlink&quot; title=&quot;Parts&quot;&gt;&lt;/a&gt;Parts&lt;/h1&gt;&lt;h2 id=&quot;Magnetic-Door-Latch&quot;&gt;&lt;a href=&quot;#Magnetic-Door-Latch&quot; c
      
    
    </summary>
    
    
      <category term="CNC" scheme="http://questionableengineering.com/tags/CNC/"/>
    
  </entry>
  
  <entry>
    <title>Grub Boot Loader Not Found</title>
    <link href="http://questionableengineering.com/2019/12/23/Grub-Boot-Loader-Not-Found/"/>
    <id>http://questionableengineering.com/2019/12/23/Grub-Boot-Loader-Not-Found/</id>
    <published>2019-12-23T19:41:32.000Z</published>
    <updated>2019-12-23T19:55:14.000Z</updated>
    
    <content type="html"><![CDATA[<p>Insert Grub console picture here </p><p>run the following commands </p><ul><li>ls</li></ul><p>Will show you all the drive parations </p><p>(hd0,gpt1)</p><ul><li>ls (hdo,gpt1)/</li></ul><p>Will give you a listing of all the files on the dive</p><ul><li>Find the drive that contains /boot</li></ul><p>(hd0,gpt1)/boot</p><ul><li>locate the grub.cfg</li></ul><p>configfile /PathToFile/grub.cfg</p><p>configfile (hd0,gpt1)/boot/grub/grub.cfg</p><ul><li><p>Grub boot menu should start.</p></li><li><p>Kernel is now running</p></li><li><p>Fix any broken packages<br>dpkg –configure -a</p></li><li><p>Check systemctl</p></li><li><p>Look for any errors that may have occured.</p></li><li><p>Fix any filesystem errors that may have occures</p></li><li><p>look in /dev/disk/by-uuid</p></li><li><p>Perform fsck on any drives that require a repair.<br>fsck /dev/disk/by-uuid/abc456</p></li><li><p>Often the grub loader cannot find the efi file</p></li><li><p>sudo apt install grub-efi-amd64</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Insert Grub console picture here &lt;/p&gt;
&lt;p&gt;run the following commands &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ls&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Will show you all the drive parations 
      
    
    </summary>
    
    
      <category term="Fixes" scheme="http://questionableengineering.com/tags/Fixes/"/>
    
  </entry>
  
  <entry>
    <title>Numpy LeNet 5 with ADAM</title>
    <link href="http://questionableengineering.com/2019/05/10/Numpy-LeNet-5-with-ADAM/"/>
    <id>http://questionableengineering.com/2019/05/10/Numpy-LeNet-5-with-ADAM/</id>
    <published>2019-05-10T14:15:12.000Z</published>
    <updated>2023-09-03T12:42:00.526Z</updated>
    
    <content type="html"><![CDATA[<p>John W Grun</p><img src="/2019/05/10/Numpy-LeNet-5-with-ADAM/image3.png" class=""><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>In this paper, a manually implemented LeNet-5 convolutional NN with an Adam optimizer written in Numpy will be presented. This paper will also cover a description of the data used to train and test the network,technical details of the implementation, the methodology of training the network and determining hyper parameters, and present the results of the effort.</p><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>LeNet-5 was created by Yuan Lecun and described  in the paper “Gradient-Based Learning Applied To Document Recognition” . LeNet-5 was one of the first convolutional neural networks used on a large scale to automatically classify hand-written digits on bank checks in the United States. Prior to LeNet, most character recognition was done by using feature engineering by hand, followed by a simple machine learning model like K nearest neighbors (KNN) or Support Vector Machines (SVM). LeNet made hand engineering features redundant, because the network learns the best internal representation from training images automatically.</p><p>This paper will cover some of the technical details of a manual Numpy implementation of LeNet-5 convolutional Neural Network including the details about the  training set, structure of the lenet-5 CNN, weights and biases initialization, optimizer, gradient descent, the loss function, and speed enhancements. The paper will also cover the methodology used during training and selecting hyperparameters as well as the performance on the test dataset.</p><h1 id="Related-work"><a href="#Related-work" class="headerlink" title="Related work"></a>Related work</h1><p>There are numerous examples of numpy implementations of LeNet 5 found across the internet but, none with more significance than any other. Lenet-5 is now a common architecture used to teach new students fundamental concepts of convolutional neural network</p><h1 id="Data-Description"><a href="#Data-Description" class="headerlink" title="Data Description"></a>Data Description</h1><img src="/2019/05/10/Numpy-LeNet-5-with-ADAM/image2.png" class=""><p>The MNIST database of handwritten digits, contains a training set of 60,000 examples, and a test set of 10,000 examples. Each example is a 28 x 28 pixel grayscale image.<br>All training and test examples of the MNIST  were converted from gray scale images to bilevel representation to simplify the function the CNN needed to learn. Only pixel positional information is required to correctly classify digits, while grayscale offers no useful additional information and only aids in increasing complexity. The labels of both the test and training examples were converted to one hot vectors to make them compatible with the softmax output and cross entropy loss function.  Both indexes of the training and test sets were further randomized to ensure each batch was a random distribution of all 10 classes.</p><h1 id="Model-Description"><a href="#Model-Description" class="headerlink" title="Model Description"></a>Model Description</h1><h2 id="Structure"><a href="#Structure" class="headerlink" title="Structure"></a>Structure</h2><img src="/2019/05/10/Numpy-LeNet-5-with-ADAM/image3.png" class=""><p>The model is  a implementation of LeNet 5 with the following structure:</p><ul><li>Input 28 x 28</li><li>Convolutional layer (Pad =  2 , Stride = 1, Activation = ReLu, Filters = 6, Size = 5)</li><li>Max Pool (Filter = 2, Stride = 2)</li><li>Convolutional layer  (Pad =  0 , Stride = 1, Activation = ReLu, Filters = 16 )</li><li>Max Pool (Filter = 2, Stride = 2)</li><li>Convolutional layer  (Pad =  0 , Stride = 1, Activation = ReLu, Filters = 120)</li><li>Fully Connected ( Size = 120, Activation = ReLu)</li><li>Fully Connected (Size = 84, Activation = ReLu)</li><li>Soft Max (  10 Classes )</li></ul><h2 id="Weight-and-bias-initialization"><a href="#Weight-and-bias-initialization" class="headerlink" title="Weight and bias initialization"></a>Weight and bias initialization</h2><p>Since the  original lenet-5 predates many of the more optimal weight initialization schemes such as Xavier or HE initialization, the weights were initialized with numpy random.randn while biases were zero filled with numpy zeros.</p><h2 id="Optimizer"><a href="#Optimizer" class="headerlink" title="Optimizer"></a>Optimizer</h2><p>At first a constant learning  rate optimizer was used for this network but, stable convergence required a very small learning rate. This small learning rate required a very long training time to achieve a reasonable accuracy on the test set. The constant learning rate optimizer was replaced with a numpy implementation of the ADAM optimizer. ADAM allowed for the use of higher learning rate that resulted in quicker and smoother convergence. The formulas that describe ADAM are shown below:</p><img src="/2019/05/10/Numpy-LeNet-5-with-ADAM/image8.png" class=""><img src="/2019/05/10/Numpy-LeNet-5-with-ADAM/image1.png" class=""><img src="/2019/05/10/Numpy-LeNet-5-with-ADAM/image4.png" class=""><img src="/2019/05/10/Numpy-LeNet-5-with-ADAM/image11.png" class=""><img src="/2019/05/10/Numpy-LeNet-5-with-ADAM/image9.png" class=""><h1 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h1><p>This implementation of LeNet-5 uses Mini-batch gradient descent. Mini-batch gradient descent is a trade-off between stochastic gradient descent (training on 1 sample at a time) and gradient descent (training on the entire training set).  In mini-batch gradient descent, the cost function (and therefore gradient) is averaged over a small number of samples. Mini batch gradient descent was selected due to its increased convergence rate and the ability to escape local minimum.</p><h2 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function"></a>Loss function</h2><p>LeNet 5 produces a 10 class categorical output representing the numbers 0 to 9.  The original LeNEt-5 used Maximum a posteriori (MAP) as the loss loss function. Cross-entropy was chosen as the loss function in this implementation instead of MAP since cross entropy appears to be the dominant loss function for similar classification problems and source code was available to check against. The formula for cross entropy loss is given below:</p><img src="/2019/05/10/Numpy-LeNet-5-with-ADAM/image10.png" class=""><h2 id="Speed-Enhancements"><a href="#Speed-Enhancements" class="headerlink" title="Speed Enhancements"></a>Speed Enhancements</h2><p>To train the CNN in a reasonable amount of time several performance enhancements had to be made.</p><img src="/2019/05/10/Numpy-LeNet-5-with-ADAM/image7.png" class=""><p>The python profiler was used to identify locations in the code that would have the largest effect on performance. The convolutional and max pooling layers consumed the majority of the running time. The running time  of the convolutional and max pool layers was decreased by first converting the single threaded functions into multithreaded functions. Processing was divided up equally across the number of threads. Once threading was confirmed to be working properly, the Numba Just in Time compiler (JIT) was employed to convert python functions into native code. Numba JIT was then liberally applied throughout the code.  These enhancements reduced the training time from over 1 day to a few hours, constituting a 6-8x speed up on average.</p><h1 id="Method-Description-And-Experimental-Procedure"><a href="#Method-Description-And-Experimental-Procedure" class="headerlink" title="Method Description And Experimental Procedure"></a>Method Description And Experimental Procedure</h1><p>The LeNet 5 model implementation  was trained on the MNIST dataset. After each training, the training loss versus epoch was plotted. The learning rate was decreased until the training loss vs epochs was a monotonically decreasing function. The number of epochs was selected to minimize the training loss while the training loss continued to decrease with every training epoch. Adjustments to the epochs sometimes also required adjustments to the learning rate to keep the training loss vs epoch a monotonically decreasing function.<br>In addition to the training loss, the prediction accuracy was computed. The accuracy was computed by the following method:<br>The input images were forward propagated through the network with the weights and biases learned during training. The class with the largest magnitude was selected as the prediction. The predicted class was compared to the label for a given input image. The percentage of correct predictions was computed across all  input images forward propagated through the network.<br>The prediction accuracy was computed for both the  training and testing sets . In a well trained network (one not underfitting or overfitting ) the test prediction accuracy should be close to the training prediction accuracy. If the training prediction accuracy is far greater than the test prediction accuracy  it is a sign the network is overfitting on the training data and failing to generalize well.<br>The batch size was selected primary upon the cache limitations of the processor. A batch size of around 32 was determined to be small enough to fit in cache while also large enough to reduce overhead from thread context switching.</p><h1 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h1><h2 id="Hyper-parameters"><a href="#Hyper-parameters" class="headerlink" title="Hyper parameters"></a>Hyper parameters</h2><p>The hyper parameters for this numpy implementation of LeNet 5 are as follows:</p><ul><li>Epochs = 20</li><li>Learning rate = 0.0002</li><li>Batch = 32</li></ul><h2 id="Training-time"><a href="#Training-time" class="headerlink" title="Training time"></a>Training time</h2><p>The total training time was brought down from 26 hours to train on the entire training set of 60000 examples to only 2.75 hours after applying speed enhancements.</p><h2 id="Training-loss"><a href="#Training-loss" class="headerlink" title="Training loss"></a>Training loss</h2><img src="/2019/05/10/Numpy-LeNet-5-with-ADAM/image12.png" class=""><p>The training loss of LeNet-5 as plotted over 20 epochs. The training loss is monotonically decreasing indicating the network is effectively learning to differentiate between the ten classes in the MNIST dataset.</p><h2 id="Accuracy"><a href="#Accuracy" class="headerlink" title="Accuracy"></a>Accuracy</h2><p>Accuracy on test set = 95.07%<br>Accuracy on Train set = 94.90%<br>The Lenet-5 implementation achieved a high accuracy on the test and train sets without a significant difference in prediction accuracy between the train and test sets which would be an indication of overfitting.</p><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>A Lenet 5 Convolutional Neural Network has been implemented only using Numpy that yields prediction accuracies over 95% on the test set. The network was trained on all 60000 examples found in the MNIST dataset and tested against the 10000 examples in the MNIST test set. The network used the standard LeNet Architecture with modifications where required. To decrease convergence time, a numpy ADAM optimizer was written. Several speed enhancements such as multi threading and just in time compilation were employed to decrease training time to a reasonable period.</p><h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><p>[1] Lavorini, Vincenzo. “Speeding up Your Code (4): in-Time Compilation with Numba.” <em>Medium</em>, Medium, 6 Mar. 2018, medium.com/@vincenzo.lavorini/speeding-up-your-code-4-in-time-compilation-with-numba-177d6849820e.<br>[2] “Convolutional Neural Networks.” <em>Coursera</em>, <a href="http://www.coursera.org/learn/convolutional-neural-networks">www.coursera.org/learn/convolutional-neural-networks</a>.<br>[3] LeCun, Yann. <em>MNIST Demos on Yann LeCun’s Website</em>, yann.lecun.com/exdb/lenet/.<br>[4] Lecun, Y., Bottou, L., Bengio, Y., &amp; Haffner, P. (1998). <em>Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278–2324.</em> doi:10.1109/5.726791<br>[5]  “MNIST Database.” Wikipedia, Wikimedia Foundation, 11 Apr. 2019, en.wikipedia.org/wiki/MNIST_database.<br>[6] “Cross Entropy.” Wikipedia, Wikimedia Foundation, 8 May 2019, en.wikipedia.org/wiki/Cross_entropy.<br>[7] “Stochastic Gradient Descent.” Wikipedia, Wikimedia Foundation, 29 Mar. 2019, en.wikipedia.org/wiki/Stochastic_gradient_descent.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;John W Grun&lt;/p&gt;
&lt;img src=&quot;/2019/05/10/Numpy-LeNet-5-with-ADAM/image3.png&quot; class=&quot;&quot;&gt;

&lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerl
      
    
    </summary>
    
    
      <category term="Computing" scheme="http://questionableengineering.com/tags/Computing/"/>
    
      <category term="Research" scheme="http://questionableengineering.com/tags/Research/"/>
    
      <category term="Machine Learning" scheme="http://questionableengineering.com/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>QuadCopterBumbleBee</title>
    <link href="http://questionableengineering.com/2019/01/20/QuadCopterBumbleBee/"/>
    <id>http://questionableengineering.com/2019/01/20/QuadCopterBumbleBee/</id>
    <published>2019-01-20T16:08:15.000Z</published>
    <updated>2023-09-02T20:41:53.352Z</updated>
    
    <content type="html"><![CDATA[<h1 id="BumbleBee-Quad-Copter"><a href="#BumbleBee-Quad-Copter" class="headerlink" title="BumbleBee Quad Copter"></a>BumbleBee Quad Copter</h1><h2 id="Frame"><a href="#Frame" class="headerlink" title="Frame"></a>Frame</h2><h3 id="BumbleBee"><a href="#BumbleBee" class="headerlink" title="BumbleBee"></a>BumbleBee</h3><h3 id="Frame-Configuration"><a href="#Frame-Configuration" class="headerlink" title="Frame Configuration"></a>Frame Configuration</h3><p>Quad X </p><img src="/2019/01/20/QuadCopterBumbleBee/MOTORS_QuadX_QuadPlus.jpg" class=""><h2 id="Controller"><a href="#Controller" class="headerlink" title="Controller"></a>Controller</h2><h3 id="Readytosky-Pixhawk-PX4-Flight-Controller-Autopilot-PIX-2-4-8-32-Bit-Flight-Control-Board-Safety-Switch-Buzzer-I2C-Splitter-Expand-Module-16GB-SD-Card"><a href="#Readytosky-Pixhawk-PX4-Flight-Controller-Autopilot-PIX-2-4-8-32-Bit-Flight-Control-Board-Safety-Switch-Buzzer-I2C-Splitter-Expand-Module-16GB-SD-Card" class="headerlink" title="Readytosky Pixhawk PX4 Flight Controller Autopilot PIX 2.4.8 32 Bit Flight Control Board+Safety Switch+Buzzer+I2C Splitter Expand Module+16GB SD Card"></a>Readytosky Pixhawk PX4 Flight Controller Autopilot PIX 2.4.8 32 Bit Flight Control Board+Safety Switch+Buzzer+I2C Splitter Expand Module+16GB SD Card</h3><img src="/2019/01/20/QuadCopterBumbleBee/Controller1.jpg" class=""><h2 id="Navigation"><a href="#Navigation" class="headerlink" title="Navigation"></a>Navigation</h2><h3 id="Readytosky-M8N-GPS-Module-Built-in-Compass-Protective-Case-with-GPS-Antenna-Mount-for-Standard-Pixhawk-2-4-6-2-4-8-Flight-Controller"><a href="#Readytosky-M8N-GPS-Module-Built-in-Compass-Protective-Case-with-GPS-Antenna-Mount-for-Standard-Pixhawk-2-4-6-2-4-8-Flight-Controller" class="headerlink" title="Readytosky M8N GPS Module Built-in Compass Protective Case with GPS Antenna Mount for Standard Pixhawk 2.4.6 2.4.8 Flight Controller"></a>Readytosky M8N GPS Module Built-in Compass Protective Case with GPS Antenna Mount for Standard Pixhawk 2.4.6 2.4.8 Flight Controller</h3><img src="/2019/01/20/QuadCopterBumbleBee/GPS4.jpg" class=""><h2 id="Remote-Control"><a href="#Remote-Control" class="headerlink" title="Remote Control"></a>Remote Control</h2><h3 id="Turnigy-TGY-I6"><a href="#Turnigy-TGY-I6" class="headerlink" title="Turnigy TGY-I6"></a>Turnigy TGY-I6</h3><h2 id="PWM-To-PPM-Conversion"><a href="#PWM-To-PPM-Conversion" class="headerlink" title="PWM To PPM Conversion"></a>PWM To PPM Conversion</h2><h3 id="usmile-PPM-Encoder-With-10pin-Input-amp-4pin-Output-Cable-For-Pixhawk-PPZ-MK-MWC-Pirate-Flight-Control"><a href="#usmile-PPM-Encoder-With-10pin-Input-amp-4pin-Output-Cable-For-Pixhawk-PPZ-MK-MWC-Pirate-Flight-Control" class="headerlink" title="usmile PPM Encoder With 10pin Input &amp; 4pin Output Cable For Pixhawk/PPZ/MK/MWC/Pirate Flight Control"></a>usmile PPM Encoder With 10pin Input &amp; 4pin Output Cable For Pixhawk/PPZ/MK/MWC/Pirate Flight Control</h3><img src="/2019/01/20/QuadCopterBumbleBee/PPM_Encoder7.jpg" class=""><h2 id="Motor-Controllers"><a href="#Motor-Controllers" class="headerlink" title="Motor Controllers"></a>Motor Controllers</h2><h3 id="Turnigy-MultiStar-V-20"><a href="#Turnigy-MultiStar-V-20" class="headerlink" title="Turnigy MultiStar V.20"></a>Turnigy MultiStar V.20</h3><p>Internal BEC provides 5V to the rest of the system<br>WARNING: If using ESC BECs to power your system you may need to disconnect all but one of the 5 volt connections from the ESC BEC. Only 1 power source! </p><h2 id="Power"><a href="#Power" class="headerlink" title="Power"></a>Power</h2><p>3300 mAH Battery </p><h2 id="Software"><a href="#Software" class="headerlink" title="Software"></a>Software</h2><h2 id="Firmware"><a href="#Firmware" class="headerlink" title="Firmware"></a>Firmware</h2><h3 id="Ardupilot"><a href="#Ardupilot" class="headerlink" title="Ardupilot"></a>Ardupilot</h3><p><a href="http://ardupilot.org/">http://ardupilot.org/</a></p><h2 id="Mission-Planner-Ground-Control"><a href="#Mission-Planner-Ground-Control" class="headerlink" title="Mission Planner ( Ground Control )"></a>Mission Planner ( Ground Control )</h2><h3 id="APM-Planner-V2-0"><a href="#APM-Planner-V2-0" class="headerlink" title="APM Planner V2.0"></a>APM Planner V2.0</h3><p><a href="http://ardupilot.org/planner2/">http://ardupilot.org/planner2/</a></p><h2 id="Pictures"><a href="#Pictures" class="headerlink" title="Pictures"></a>Pictures</h2><h2 id="Frame-1"><a href="#Frame-1" class="headerlink" title="Frame"></a>Frame</h2><h3 id="Testing"><a href="#Testing" class="headerlink" title="Testing"></a>Testing</h3><img src="/2019/01/20/QuadCopterBumbleBee/20190119_164818.jpg" class=""><h2 id="Motor-Connections"><a href="#Motor-Connections" class="headerlink" title="Motor Connections"></a>Motor Connections</h2><h3 id="Front-Left"><a href="#Front-Left" class="headerlink" title="Front Left"></a>Front Left</h3><img src="/2019/01/20/QuadCopterBumbleBee/20190119_164831.jpg" class=""><h3 id="Front-Right"><a href="#Front-Right" class="headerlink" title="Front Right"></a>Front Right</h3><img src="/2019/01/20/QuadCopterBumbleBee/20190119_164842.jpg" class=""><h3 id="Rear-Left"><a href="#Rear-Left" class="headerlink" title="Rear Left"></a>Rear Left</h3><img src="/2019/01/20/QuadCopterBumbleBee/20190119_164852.jpg" class=""><h3 id="Rear-Right"><a href="#Rear-Right" class="headerlink" title="Rear Right"></a>Rear Right</h3><img src="/2019/01/20/QuadCopterBumbleBee/20190119_164848.jpg" class="">]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;BumbleBee-Quad-Copter&quot;&gt;&lt;a href=&quot;#BumbleBee-Quad-Copter&quot; class=&quot;headerlink&quot; title=&quot;BumbleBee Quad Copter&quot;&gt;&lt;/a&gt;BumbleBee Quad Copter&lt;/
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>React_Native_Watch_Limit_Fix</title>
    <link href="http://questionableengineering.com/2017/12/30/React-Native-Watch-Limit-Fix/"/>
    <id>http://questionableengineering.com/2017/12/30/React-Native-Watch-Limit-Fix/</id>
    <published>2017-12-31T00:02:42.000Z</published>
    <updated>2017-12-31T00:08:59.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Ubuntu-Watch-filesystem-limit-Work-Around"><a href="#Ubuntu-Watch-filesystem-limit-Work-Around" class="headerlink" title="Ubuntu Watch filesystem limit Work Around"></a>Ubuntu Watch filesystem limit Work Around</h1><p>In the terminal run </p><p>sudo gedit /etc/sysctl.conf</p><pre><code>fs.inotify.max_user_instances=524288fs.inotify.max_user_watches=524288fs.inotify.max_queued_events=524288</code></pre><p>Reboot for changes to take effect. </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Ubuntu-Watch-filesystem-limit-Work-Around&quot;&gt;&lt;a href=&quot;#Ubuntu-Watch-filesystem-limit-Work-Around&quot; class=&quot;headerlink&quot; title=&quot;Ubuntu Wat
      
    
    </summary>
    
    
      <category term="Fixes" scheme="http://questionableengineering.com/tags/Fixes/"/>
    
      <category term="React Native" scheme="http://questionableengineering.com/tags/React-Native/"/>
    
  </entry>
  
  <entry>
    <title>Electrical_Enclosures_With_OpenScad</title>
    <link href="http://questionableengineering.com/2017/12/30/Electrical-Enclosures-With-OpenScad/"/>
    <id>http://questionableengineering.com/2017/12/30/Electrical-Enclosures-With-OpenScad/</id>
    <published>2017-12-30T18:38:54.000Z</published>
    <updated>2020-09-04T03:38:43.975Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Using-open-scad-to-produce-backplates-for-electrical-enclosures"><a href="#Using-open-scad-to-produce-backplates-for-electrical-enclosures" class="headerlink" title="Using open scad to produce backplates for electrical enclosures"></a>Using open scad to produce backplates for electrical enclosures</h1><p>I needed a backplate for an electrical enclosure. Instead of waiting a few days I decided to 3d print one. </p><img src="/2017/12/30/Electrical-Enclosures-With-OpenScad/20171230_140156.jpg" class=""><p>Figure 1: NEMA4X Electrical Enclosure</p><span id="more"></span><p>Tools:<br>    * Micrometer<br>    * Calculator<br>    * OpenScad<br>    * Cura </p><p>OpenScad code:</p><pre><code>echo(version=version());difference() &#123;color(&quot;red&quot;)    translate([0, -0, 0])        linear_extrude(height = 2)            square([121, 121], center = true);    translate([-60.5,-60.5,0])        linear_extrude(height = 2)            square([30,30], center = true);    translate([60.5,-60.5,0])        linear_extrude(height = 2)            square([30,30], center = true);    translate([60.5,60.5,0])        linear_extrude(height = 2)            square([30,30], center = true);    translate([-60.5,60.5,0])        linear_extrude(height = 2)            square([30,30], center = true);&#125;</code></pre><img src="/2017/12/30/Electrical-Enclosures-With-OpenScad/Screenshot%20from%202017-12-30%2014-11-16.png" class=""><p>Figure 2: OpenScad</p><img src="/2017/12/30/Electrical-Enclosures-With-OpenScad/Screenshot%20from%202017-12-30%2014-12-14.png" class=""><p>Figure 3: Cura</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Using-open-scad-to-produce-backplates-for-electrical-enclosures&quot;&gt;&lt;a href=&quot;#Using-open-scad-to-produce-backplates-for-electrical-enclosures&quot; class=&quot;headerlink&quot; title=&quot;Using open scad to produce backplates for electrical enclosures&quot;&gt;&lt;/a&gt;Using open scad to produce backplates for electrical enclosures&lt;/h1&gt;&lt;p&gt;I needed a backplate for an electrical enclosure. Instead of waiting a few days I decided to 3d print one. &lt;/p&gt;
&lt;img src=&quot;/2017/12/30/Electrical-Enclosures-With-OpenScad/20171230_140156.jpg&quot; class=&quot;&quot;&gt;
&lt;p&gt;Figure 1: NEMA4X Electrical Enclosure&lt;/p&gt;
    
    </summary>
    
    
      <category term="Electrical" scheme="http://questionableengineering.com/tags/Electrical/"/>
    
      <category term="OpenScad" scheme="http://questionableengineering.com/tags/OpenScad/"/>
    
      <category term="Mechanical" scheme="http://questionableengineering.com/tags/Mechanical/"/>
    
  </entry>
  
  <entry>
    <title>Peer to Peer Domain Name System (P2PN-DNS)</title>
    <link href="http://questionableengineering.com/2017/12/29/Peer-to-Peer-Domain-Name-System-P2PN-DNS/"/>
    <id>http://questionableengineering.com/2017/12/29/Peer-to-Peer-Domain-Name-System-P2PN-DNS/</id>
    <published>2017-12-29T19:49:34.000Z</published>
    <updated>2023-08-30T03:51:31.191Z</updated>
    
    <content type="html"><![CDATA[<p>John Grun</p><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>In this paper, we introduce the Peer to Peer  Network Domain Name System (P2PN-DNS) a distributed implementation of the<br>Domain Name System (DNS) that hopes to offer solutions to shortcomings of the current DNS such as susceptibility to outages while mitigating attempts of domain name censorship, and provide a fault tolerant name lookup service for software containers that is independent of upstream servers. Performance metrics including the time to reach consistency between nodes, service availability in lieu of loss of nodes, and average response time to DNS queries will be examined.</p><h2 id="I-Introduction"><a href="#I-Introduction" class="headerlink" title="I. Introduction"></a>I. Introduction</h2><p>The  Domain Name System (DNS) is a critical element of internet infrastructure that associates IP addresses to human readable domain names. E.g Google.com is located a IP:172.217.6.238. When DNS was introduced in 1987 with the RFC 1034 /RFC 1035 17/18 standards, the internet consisted of relatively few computers where a simple hierarchical tree model functioned well.<br>As the internet scaled, DNS was expanded to accommodate the exponential growth in computers. In this regard, DNS has been a tremendous success but, it is not without serious flaws, most notably respectability to attacks on or failures of the Root DNS servers. A Root DNS Server acts as the authoritative source for the entire network.</p><img src="/2017/12/29/Peer-to-Peer-Domain-Name-System-P2PN-DNS/Figure1.png" class=""><p>Figure 1: DNS tree structure <sup> 24</sup></p><p>In part due to the tree structure of DNS, there are only thirteen DNS Root Servers in the world. An attacker only needs to target a few DNS root servers to cripple IP address to domain name translation in an entire region effectively blocking internet access for most users. Attacks against DNS Root Servers have occurred and appear to be becoming more frequent from various entities, such as hackers, or state actors. It is also quite conceivable that DNS would be a target in wartime. Additionally, centrally located servers are vulnerable to regional events such as power outages or natural disasters.</p><p>Another issue that has been seen in the wild is the censorship of websites by state, corporate, or other actors via DNS poisoning. DNS poisoning blocks access to websites by disrupting the domain name lookup between a DNS resolver and the regional DNS server. E.g Google.com is located at IP:172.217.6.238. China <sup> 26 </sup> and Iran <sup> 25 </sup> have both used DNS poisoning to block access to internet domains. Corporations such as Charter, Comcast, and Optonline <sup>3</sup>  have used DNS poisoning to reroute search results away from competitor websites or to collect advertising profits.</p><p>An additional limitation of the existing DNS system is a lack of software container support.<br>Existing DNS solutions for software containers either rely upon a DNS repeater or upon a standard DNS server. These methods simply extend the existing DNS system. If the upstream DNS is made inoperable or poisoned, the containers will be affected as well. This dependency upon existing DNS introduces a  single point of failure into what would otherwise be fault tolerant architecture.</p><p>The aforementioned problems encountered are a consequence of the centralized hierarchical architecture of DNS. A different architecture can be defined to address these problems while providing the same functionality. We propose to build a decentralized Peer to Peer Network DNS (P2PN-DNS) that will not rely on central servers. We intended to take the best practices from existing distributed robust protocols such as bitTorrent and bitcoin to accomplish our goal. Also, each P2PN-DNS node should be able to contain an internal store of the domain name IP address relations without relying on additional software or servers.</p><h2 id="II-Related-and-Previous-Work"><a href="#II-Related-and-Previous-Work" class="headerlink" title="II. Related and Previous Work"></a>II. Related and Previous Work</h2><p>There have been several different methods over the years to address some or all of the aforementioned problems with DNS.</p><p>Amazon Web Services (AWS) offers a implementation of DNS known as Amazon Route 53. Route 53 is believed to be a distributed DNS system but, architectural details have not been forthcoming from Amazon.<sup>27</sup></p><p>Another project DC/OS, (the Distributed Cloud Operating System) contains an internal DNS repeater. While the DC/OS DNS repeater is distributed on the internal network and consists of multiple nodes, it is not a true distributed peer to peer DNS. The DC/OS DNS is a redundant DNS system that acts as a DNS forwarder from a DNS server further up the DNS tree making it vulnerable to the same issues as DNS.28 See <a href="https://dcos.io/">https://dcos.io/</a></p><p>A third related work, Kad Node claims to be a small peer to peer DNS resolver or to act as a DNS proxy. Kad node stores DNS records in a distributed hash table, similar to our proposal but, it differs in that it does not appear to utilize a hash based DNS update ordering scheme. At the writing of this paper Kad Node appears to be inactive.<sup> 29</sup> See Kad Node at <a href="https://github.com/kadtools/kad">https://github.com/kadtools/kad</a></p><h2 id="III-Contribution"><a href="#III-Contribution" class="headerlink" title="III. Contribution"></a>III. Contribution</h2><h3 id="Technical-Problems"><a href="#Technical-Problems" class="headerlink" title="Technical Problems"></a>Technical Problems</h3><p>The main technical concerns affecting a distributed DNS are the same as those encountered in any system where information is distributed between disparate nodes, namely  data consistency, availability, and network partition tolerance. As stated by the CAP (Consistency, Availability, and Partition Tolerance) theorem, it is impossible for a distributed data store to simultaneously provide all three of the guarantees of consistency, availability, and partition tolerance at any given time. This implies compromises must be made between the three. In the case of a distributed DNS the decision as to which guarantees to support and which to neglect is relatively straight forward. In a real world environment, computers crash, network connections fail, and infrastructure can be disabled, thus network partition tolerance is a requirement of any realistic distributed DNS. As a critical service of internet infrastructure, DNS must be always available for the internet to operate properly. Thus availability is a required guarantee as well.</p><p>With partition tolerance and availability as required guarantees, continuous consistency becomes impossible to guarantee according to the CAP theorem. In the case of DNS, continuous consistency is not a requirement and eventual consistency is more than sufficient. In fact, currently a DNS record updates are eventually consistent and  can take up to 24 hours to complete.</p><p>Partition tolerance and availability can both be addressed by designing each node to operate independently of all the others on the network. The independent nodes need only exchange update information to ensure eventual consistency of the DNS records. In this architecture, the more nodes added to a network, the more reliable the system will become.</p><p>In a distributed system relying upon eventual consistency to make data agree across nodes, the issue of order of updates arises, since there is the possibility of updates arriving at other nodes in a different order than they must be applied to ensure agreement between nodes.<br>This can be addressed by writing updates to a commit log prior to writing the DNS update. A commit log is a data structure that keeps track of the operations to be performed in first in first out (FIFO) order. When a new DNS record update is received by a node, the update is first written to the commit log. While changes are in the commit log, actions can be taken to ensure the correct ordering of the updates. The ordering of the commits can be verified and corrected by comparing timestamps or by using a hashing based scheme. An update will only be removed from the commit log once the node has finished updating the DNS record.</p><img src="/2017/12/29/Peer-to-Peer-Domain-Name-System-P2PN-DNS/Figure2.png" class=""><p>Figure 2: Commit Log Functionality <sup>16</sup></p><p>There are some properties of DNS record updates that allow for some simplifications.<br>Since the update history of each domain name in DNS is independent of all other domain names, we do not need to ensure ordering between different domain names. This property can be utilized to simplify the consistency requirement since it greatly limits the amount of possible combinations in ordering. We need only establish an update chain on a per domain name basis.<br>The update history can be established with  timestamping. Each update is time stamped, and if every node is synced to the same clock the order of updates can be ordered correctly. If the nodes do not have a common clock source this method fails to guarantee the correct update ordering. This ordering problem is what data structures and algorithms such as Merkle trees and blockchains were developed to solve. A Blockchain or Merkle tree takes a hash of a data record, then the next data update in line is a hash of the new update combined with the previous hash. The update received by a node can be confirmed ordered correctly by hashing the previous hash with the current update and comparing the result. If the hash is the same, the DNS record can be updated. If the hash is incorrect a Quorum can be called to reach a consensus between nodes. Since a record update is only concerned about the most recent update and is not dependent upon the entire history of the update chain the ordering requirement can be relaxed to only include the last few updates. In this case, a Quorum can serve the purpose of correcting out of order entries. This situation may arise if some nodes do not receive a DNS update or network issues cause updates to arrive in the wrong order.</p><p>The next technical challenge is how to store the DNS records. Since DNS are retrieved based upon the domain name, the most logical method is a simple key value store, where the domain name is used as the key and the corresponding ip address is the value.</p><p>Another issue that arises in the real world is the need to automatically find peers. In a small scale system, manually assigning peer address is possible but, as the system scales this method quickly becomes untenable. Nodes must employ a method to locate each other without the intervention of humans. One such method that has proven to be quite effective in other distributed applications is the distributed hash table (DHT). A distributed hash table (DHT) provides a lookup service similar to a hash table: (<em>key</em>, <em>value</em>) pairs are stored in a DHT, and any participating node can efficiently retrieve the value associated with a given key. Responsibility for maintaining the mapping from keys to values is distributed among the nodes, in such a way that a change in the set of participants causes a minimal amount of disruption. This allows a DHT to scale to an extremely large numbers of nodes while handling continual node arrivals, and departures.</p><img src="/2017/12/29/Peer-to-Peer-Domain-Name-System-P2PN-DNS/Figure3.png" class=""><p>Figure 3: Distributed Hash Table Functionality <sup>15</sup></p><p>Possibly the hardest technical problem to address in a distributed system is known as the “Trust Problem.” The trust problem brings forth the question of which node is friendly, and which is malicious. If this implementation was utilized on the open web, the trust problem can be addressed with strategies such as proof of work as employed by technologies such as Blockchain. Nevertheless, if only running on a isolated network, methods such as trusted tokens would are viable. This problem is beyond the scope of this paper but, the authors felt it was important enough to mention and it will have to be addressed in future releases.</p><h2 id="IV-Algorithm-and-Implementation"><a href="#IV-Algorithm-and-Implementation" class="headerlink" title="IV.  Algorithm and Implementation"></a>IV.  Algorithm and Implementation</h2><p>The implementation of P2PN-DNS involved the union of several aforementioned key concepts in distributed computing, the key-value store, distributed hash table, and the commit log.</p><img src="/2017/12/29/Peer-to-Peer-Domain-Name-System-P2PN-DNS/Figure4.png" class=""><p>Figure 4: Implementation Block Diagram</p><p>At the most basic level DNS can be viewed as a  key value store where the domain name serves as the key and the IP address serves as the value. In practice, the DNS domain name to ip address relation is called a resource record and may contain a plethora of data including IP address, CNAME, TXT, etc. For our demonstration only a simple domain name to ip address was implemented.</p><p>The main data structure enabling P2PN-DNS is the distributed hash table. In theory a distributed hash table appears simple but, in practice the implementation of the data structure and overlay network can be very labor and time intensive. There was no reason to reinvent the wheel for P2PN-DNS so, OpenDHT was used for the DHT. OpenDHT aligns well with the scope and goals of P2PN-DNS while bundling in support for other desirable features such as IPv4 and IPv6, public key cryptography, distributed shared keys, and an overall concise, and clear approach. OpenDHT can be found at <a href="https://github.com/savoirfairelinux/opendht">https://github.com/savoirfairelinux/opendht</a></p><p>Since OpenDHT was originally targeted similar distributed applications, the key-value store and commit log functionality were already present and did not have to be implemented independently.</p><p>The other major facet of P2PN-DNS was the implementation of the DNS protocol. DNS protocol support was based upon a bare bones implementation of DNS called SimpleDNS. The C source code had to be heavily modified to make it compatible with the C++ elements of P2PN-DNS. Most eventenly the use of C++ 11 std::function as callbacks. Additionally, the DNS update (22) message had to be implemented. The DNS update (22) message did not become a public facing feature in the current DNS system and as such it is not included in most DNS resolvers. Systems that do implement a DNS update scheme are called Dynamic Dns or (DDNS) and have accompanying attenication to update a DNS record. (DDNS) is not directly compatible with standard DNS and relies upon an authoritative entity to make the DNS update to the rest of the Domain Name System. In the interests of time and simplicity, a minimal DNS update scheme was implemented. This shortcoming will be rectified in future releases. Please see for the original SimpleDNS source code at <a href="https://github.com/mwarning/SimpleDNS">https://github.com/mwarning/SimpleDNS</a></p><p>The ordering of the updates is determined strictly based upon timestamp in this release. This timestamp method works as long as all the nodes are time synced. This is not a valid assumption in a real world environment as nodes may be operating on seperate networks with differing time sources. In future releases a hash bashed ordering scheme as mentioned in Section 3 will be investigated.</p><p>The source code for the P2PN-DNS and further documentation can be found at: <a href="https://github.com/P2PN-DNS/P2PN-DNS">https://github.com/P2PN-DNS/P2PN-DNS</a></p><h2 id="V-Results-and-Analysis"><a href="#V-Results-and-Analysis" class="headerlink" title="V.  Results and Analysis"></a>V.  Results and Analysis</h2><h3 id="Experiment-and-Evaluation"><a href="#Experiment-and-Evaluation" class="headerlink" title="Experiment and Evaluation"></a>Experiment and Evaluation</h3><p>There are a few metrics that matter in a real world application such as the response time to DNS queries, service availability in lieu of loss of nodes, and the average time required to sync records across nodes. For our experiments we propose to examine these metrics and compare, where applicable, to the current DNS system. Dnsmasq will serve as the comparison benchmark as it is a widely deployed DNS forwarder for DNS queries.</p><p>To measure the response time of the nodes to a DNS request, a DNS request was sent to a  P2PN-DNS node via the dig utility, and the record response was recorded. The time taken from request to response was recorded by Wireshark. The same method was employed against DNS(dnsmasq). Five common domain names were chosen; google.com, Amazon.com, Nytimes.com, alibaba.com, and stackoverflow.com. Three samples were taken for each domain name on both P2PN-DNS and dnsmasq to establish a trend and to compensate for outliers. This resulted in 15 queries per dnsmasq and 15 queries for P2PN-DNS. Dnsmasq was running on same network as P2PN-DNS. P2PN-DNS records were added via the DNS update message prior to running the experiment.</p><img src="/2017/12/29/Peer-to-Peer-Domain-Name-System-P2PN-DNS/Figure5.png" class=""><p>Figure 5: Query Response Times of DNS versus P2PN-DNS</p><p>The first request for each domain name to Dnsmasq was of longer duration.This was due to Dnsmasq requesting current information from a higher tier DNS server( Google DNS 8.8.8.8). The second and third requests were served from the Dnsmasq local cache, hence the much shorter duration in response time. P2PN-DNS had slightly longer response time than the Dnsmasq cached response but, less than the first non cached result. This behavior was to be expected as P2PN-DNS has to search the DHT on every lookup and currently does not have local caching enabled. Response time of P2PN-DNS could be improved by enabling local caching in future releases.</p><p>To test to the availability of P2PN-DNS in lieu of loss of nodes, is to observe the behavior of the P2PN-DNS nodes when nodes disappear from the network. To conduct this experiment, five nodes were started. A DNS record update message was sent to one of the nodes. The nodes were allowed to reach a consistent state where all nodes are informed of the updated record as observed by querying each node for the updated record. One node was be taken offline at a time. Each time a node was removed, the DNS records were checked for consistency between the remaining nodes.</p><img src="/2017/12/29/Peer-to-Peer-Domain-Name-System-P2PN-DNS/Figure6.png" class=""><p>Figure 6: Progression of loss of nodes to test availability</p><p>The DNS record was returned correctly even after only one node of the original five remained. This shows that the P2PN-DNS can fulfill the availability and partition tolerance guarantees even as nodes are removed from the network.</p><p>To observe the amount of time required to sync records across nodes, the timestamp in the commit log was compared between two different nodes. The difference in the arrival timestamp between the two nodes is directly correlated to the time required to sync records. To ensure accurate timestamping, all nodes were  tied to an common clock and synced with  Network Time Protocol (NTP).</p><img src="/2017/12/29/Peer-to-Peer-Domain-Name-System-P2PN-DNS/Figure7.png" class=""><p>Figure 7: Syslog output from two nodes</p><p>In the figure above, the syslog output of two nodes can be observed. To produce these results, a DNS update packet was sent to one node. Syslog was monitored for logs containing information about the record update between the two nodes. The update to a record can be seen in one node and in less than one second later, the update is available on the other node. Network capabilities have an impact on the overall record sync time and can affect time jitter. The network variability(jitter) timing issue was avoided by running the nodes on the same network with a common NTP server.</p><h2 id="VI-Conclusion"><a href="#VI-Conclusion" class="headerlink" title="VI.  Conclusion"></a>VI.  Conclusion</h2><p>With our implementation of a distributed DNS we were able to find a workable tradeoff between consistency, availability, and partition tolerance. By conducting thorough experiments and analysis, we showed that P2PN-DNS can guarantee eventually consistency, availability, and partition tolerance while also providing a comparable amount time required to process DNS queries as compared to existing DNS solutions such as DNSmasq.P2PN-DNS was shown to be available even as nodes were removed giving credence to the claim that P2PN-DNS would be less susceptible than current DNS to regional outages or purposeful attacks.<br>Additionally, the distributed nature of P2PN-DNS makes it applicable for software containers which would benefit from a fault tolerant solution such as P2PN-DNS.</p><h2 id="VII-References"><a href="#VII-References" class="headerlink" title="VII.  References"></a>VII.  References</h2><p>[1] “Domain Name System”. En.wikipedia.org. N.p., 2017. Web. 2 November 2017.<a href="https://en.wikipedia.org/wiki/Domain_Name_System">https://en.wikipedia.org/wiki/Domain_Name_System</a><br>[2] “Distributed Denial of Service Attacks on Root Nameservers ”. En.wikipedia.org. N.p., 2017. Web. 2 November 2017. <a href="https://en.wikipedia.org/wiki/Distributed_denial-of-service_attacks_on_root_nameservers">https://en.wikipedia.org/wiki/Distributed_denial-of-service_attacks_on_root_nameservers</a><br>[3] “I Fought My ISPS Bad Behavior and Won”. Eric Helgeson. Web. 2 November 2017. <a href="https://erichelgeson.github.io/blog/2013/12/31/i-fought-my-isps-bad-behavior-and-won/">https://erichelgeson.github.io/blog/2013/12/31/i-fought-my-isps-bad-behavior-and-won/</a><br>[4] Eckersley, Technical Analysis by Peter. “Widespread Hijacking of Search Traffic in the United States.” Electronic Frontier Foundation, 14 Oct. 2011. Web. 2 November 2017. <a href="https://www.eff.org/deeplinks/2011/07/widespread-search-hijacking-in-the-us">https://www.eff.org/deeplinks/2011/07/widespread-search-hijacking-in-the-us</a><br>[5] “Transaction Log”. En.wikipedia.org. N.p., 2017. Web. 2 November 2017. <a href="https://en.wikipedia.org/wiki/Transaction_log">https://en.wikipedia.org/wiki/Transaction_log</a><br>[6] “Merkle Tree”. En.wikipedia.org. N.p., 2017. Web. 2 November 2017.<br><a href="https://en.wikipedia.org/wiki/Merkle_tree">https://en.wikipedia.org/wiki/Merkle_tree</a><br>[7]  Kangasharju, Jussi. Chapter 4: Distributed Systems: Replication and Consistency. N.p., 2017. Web. 7 November 2017. <a href="https://www.cs.helsinki.fi/webfm_send/1256">https://www.cs.helsinki.fi/webfm_send/1256</a><br>[8] “Blockchain”. En.wikipedia.org. N.p., 2017. Web. 7 November 2017. <a href="https://en.wikipedia.org/wiki/Blockchain">https://en.wikipedia.org/wiki/Blockchain</a><br>[9] Jacquin, Ludovic, et al. “The Trust Problem in Modern Network Infrastructures.” SpringerLink, Springer, Cham, 28 Apr. 2015. N.p., 2017. Web. 7 November 2017.  <a href="https://link.springer.com/chapter/10.1007/978-3-319-25360-2_10">https://link.springer.com/chapter/10.1007/978-3-319-25360-2_10</a><br>[10] “ACID”. En.wikipedia.org. N.p., 2017. Web. 8 November 2017. <a href="https://en.wikipedia.org/wiki/ACID">https://en.wikipedia.org/wiki/ACID</a><br>[11] DataStax Academy Follow. “A Deep Dive Into Understanding Apache Cassandra.”LinkedIn SlideShare, 25 Sept. 2013. N.p., 2017. Web. 2 December 2017.  <a href="https://www.slideshare.net/planetcassandra/a-deep-dive-into-understanding-apache-cassandra">https://www.slideshare.net/planetcassandra/a-deep-dive-into-understanding-apache-cassandra</a><br>[12] “Peer-to-Peer (P2P) Systems.” SlidePlayer. N.p., 2017. Web. 2 December 2017 <a href="http://slideplayer.com/slide/4168557/">http://slideplayer.com/slide/4168557/</a><br>[13] “Non-Transitive Connectivity and DHTs “<a href="https://www.usenix.org/legacy/events/worlds05/tech/full_papers/freedman/freedman_html/index.html">https://www.usenix.org/legacy/events/worlds05/tech/full_papers/freedman/freedman_html/index.html</a><br>[14] “Amazon Route 53”. En.wikipedia.org. N.p., 2017. Web. 6 December 2017.<br><a href="https://en.wikipedia.org/wiki/Amazon_Route_53">https://en.wikipedia.org/wiki/Amazon_Route_53</a><br>[15] “Distributed hash table” .En.wikipedia.org. N.p., 2017. Web. 6 December 2017. <a href="https://en.wikipedia.org/wiki/Distributed_hash_table">https://en.wikipedia.org/wiki/Distributed_hash_table</a><br>[16] “FIFO (computing and electronics)” .En.wikipedia.org. N.p., 2017. Web. 6 December 2017. <a href="https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)">https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)</a><br>[17] “RFC 1034  DOMAIN NAMES - CONCEPTS AND FACILITIES”, N.p., 2017. Web. 2 November 2017. <a href="https://www.ietf.org/rfc/rfc1034.txt">https://www.ietf.org/rfc/rfc1034.txt</a><br>[18] “RFC 1035 DOMAIN NAMES - IMPLEMENTATION AND SPECIFICATION” , N.p., 2017. Web. 2 November 2017. <a href="https://www.ietf.org/rfc/rfc1035.txt">https://www.ietf.org/rfc/rfc1035.txt</a><br>[19] “Embedded DNS server in user-defined networks” N.p., 2017. Web. 2 November 2017. <a href="https://docs.docker.com/engine/userguide/networking/configure-dns/">https://docs.docker.com/engine/userguide/networking/configure-dns/</a><br>[20] “OpenDHT”   Web. 2 November 2017. <a href="https://github.com/savoirfairelinux/opendht">https://github.com/savoirfairelinux/opendht</a><br>[21] “SimpleDNS: Web. 2 November 2017. <a href="https://github.com/mwarning/SimpleDNS">https://github.com/mwarning/SimpleDNS</a><br>[22] “  Dynamic Updates in the Domain Name System (DNS UPDATE)” Web. 2 November 2017. <a href="https://tools.ietf.org/html/rfc2136">https://tools.ietf.org/html/rfc2136</a><br>[23] “ You can’t Peer to Peer the DNS”<br><a href="https://nohats.ca/wordpress/blog/2012/04/09/you-cant-p2p-the-dns-and-have-it-too/">https://nohats.ca/wordpress/blog/2012/04/09/you-cant-p2p-the-dns-and-have-it-too/</a><br>[24] “DNS Server”<br><a href="https://gitlearning.wordpress.com/2015/06/23/dns-server/">https://gitlearning.wordpress.com/2015/06/23/dns-server/</a><br>[25] “Internet censorship in Iran” <a href="https://en.wikipedia.org/wiki/Internet_censorship_in_Iran">https://en.wikipedia.org/wiki/Internet_censorship_in_Iran</a><br>[26] “Great Firewall”<br><a href="https://en.wikipedia.org/wiki/Great_Firewall">https://en.wikipedia.org/wiki/Great_Firewall</a><br>[27] “ Amazon Route 53”<br><a href="https://en.wikipedia.org/wiki/Amazon_Route_53">https://en.wikipedia.org/wiki/Amazon_Route_53</a><br>[28] “DC/OS” <a href="https://dcos.io/">https://dcos.io/</a><br>[29] “Kad Node” <a href="https://github.com/kadtools/kad">https://github.com/kadtools/kad</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;John Grun&lt;/p&gt;
&lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;p&gt;In this paper, we introduce t
      
    
    </summary>
    
    
      <category term="Computing" scheme="http://questionableengineering.com/tags/Computing/"/>
    
      <category term="Research" scheme="http://questionableengineering.com/tags/Research/"/>
    
      <category term="Distributed Computing" scheme="http://questionableengineering.com/tags/Distributed-Computing/"/>
    
  </entry>
  
  <entry>
    <title>Hexo Asset Posts Work Around</title>
    <link href="http://questionableengineering.com/2017/12/26/Hexo-Asset-Posts-Work-Around/"/>
    <id>http://questionableengineering.com/2017/12/26/Hexo-Asset-Posts-Work-Around/</id>
    <published>2017-12-27T01:15:57.000Z</published>
    <updated>2023-09-02T13:40:59.855Z</updated>
    
    <content type="html"><![CDATA[<p>Even though Hexo suports markdown, the current asset folders implmention is hacky at best.<br>It does not allow for additional fields. Without the asset_path or image tag your image will often not show up on the index page.<br>The following code will allow you to set properties and display the image on the index page </p><pre><code>&lt;img src=&quot;&#123;% asset_path image_0.png %&#125;&quot; style=&quot;width: 90%;&quot;/&gt;</code></pre><p>A better way would be to include the markdown file in the Asset Folder. </p><span id="more"></span>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Even though Hexo suports markdown, the current asset folders implmention is hacky at best.&lt;br&gt;It does not allow for additional fields. Without the asset_path or image tag your image will often not show up on the index page.&lt;br&gt;The following code will allow you to set properties and display the image on the index page &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;img src=&amp;quot;&amp;#123;% asset_path image_0.png %&amp;#125;&amp;quot; style=&amp;quot;width: 90%;&amp;quot;/&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A better way would be to include the markdown file in the Asset Folder. &lt;/p&gt;
    
    </summary>
    
    
      <category term="Fixes" scheme="http://questionableengineering.com/tags/Fixes/"/>
    
      <category term="Hexo" scheme="http://questionableengineering.com/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>Investigation of Memory Dependence Strategies</title>
    <link href="http://questionableengineering.com/2017/09/15/Investigation-of-Memory-Dependence-Strategies/"/>
    <id>http://questionableengineering.com/2017/09/15/Investigation-of-Memory-Dependence-Strategies/</id>
    <published>2017-09-16T01:43:08.000Z</published>
    <updated>2023-09-02T16:14:27.100Z</updated>
    
    <content type="html"><![CDATA[<img src="/2017/09/15/Investigation-of-Memory-Dependence-Strategies/image7.png" class=""><h2 id="Computer-Architecture"><a href="#Computer-Architecture" class="headerlink" title="Computer Architecture"></a>Computer Architecture</h2><h2 id="Investigation-of-Memory-Dependence-Prediction-Strategies-with-SimpleScalar"><a href="#Investigation-of-Memory-Dependence-Prediction-Strategies-with-SimpleScalar" class="headerlink" title="Investigation of Memory Dependence Prediction Strategies with SimpleScalar"></a>Investigation of Memory Dependence Prediction Strategies with SimpleScalar</h2><h3 id="Lorenzo-Allas-John-Grun-Sanandeesh-Kamat"><a href="#Lorenzo-Allas-John-Grun-Sanandeesh-Kamat" class="headerlink" title="Lorenzo Allas, John Grun, Sanandeesh Kamat"></a>Lorenzo Allas, John Grun, Sanandeesh Kamat</h3><img src="/2017/09/15/Investigation-of-Memory-Dependence-Strategies/image5.png" class=""><img src="/2017/09/15/Investigation-of-Memory-Dependence-Strategies/image12.jpg" class=""><h1 id="0-0-Abstract"><a href="#0-0-Abstract" class="headerlink" title="0.0 Abstract"></a>0.0 Abstract</h1><p>A dynamically scheduled processor may default to in-order execution of Load/Store instructions to avoid Memory Order Violations. This is because, loads executed out of order may be dependent upon prior stores, the addresses of which were initially unknown. To overcome the potentially wasted clock cycles of conservatively stalled loads, known as False Dependencies, Memory Dependence Predictor (MDP) schemes have been developed. This paper demonstrates the implementation of two experimental MDP schemes, Store Sets and Counting Dependence Predictor (CDP) within the SimpleScalar framework. In addition, it demonstrates two baseline MDP schemes, No Speculation and Naive Speculation. The conceptual overview, the software implementation details, as well as quantitative simulation results are provided. The performance of these MDP schemes has been evaluated in terms of three metrics: the number of Memory Order Violations, the number of False Dependencies, and the average IPC. Although the results did not indicate a performance enhancement in terms of execution time, they do demonstrate expected behavior in terms of Memory Order Violations and False Dependencies. Possible implementation shortcomings, and future alterations are later proposed.</p><span id="more"></span><h1 id="1-0-Introduction"><a href="#1-0-Introduction" class="headerlink" title="1.0 Introduction"></a>1.0 Introduction</h1><h2 id="1-1-The-Question-To-Issue-Load-or-not-to-Issue-Load"><a href="#1-1-The-Question-To-Issue-Load-or-not-to-Issue-Load" class="headerlink" title="1.1 The Question: To Issue Load or not to Issue Load?"></a>1.1 The Question: To Issue Load or not to Issue Load?</h2><p>In a pipelined In-Order execution processor, if an instruction is dependent upon the result of a previously issued instruction then entire processor pipeline must be stalled. This has the effect of drastically reducing the throughput of the processor by, stalling later instructions that have no dependence upon the stalling instruction. To circumvent the performance limitations inherent in the In-Order pipelined processor designs,  dynamic scheduling (Out of Order execution) was introduced. Dynamic scheduling works by allowing instructions to issue out of order. Thus if an instruction is issued and is dependent upon the result of a previous instruction, later instructions do not need to wait. Later non-dependent instructions are allowed to issue as long as the processor has available resources (e.g. Adder, Multiplier, FPU, etc.). Inconveniently, the target memory addresses of memory access instructions (i.e. load/store) are not resolved until after issue. Therefore, earlier implementations of dynamic scheduling (e.g.Tomasulo) issued loads and stores in program order to prevent memory order violations. Memory Order Violations occur when loads and store operate on the same memory address in the incorrect order and thus produce incorrect program execution. While this method ensured the correct program execution, the benefits of dynamic scheduling were not realized for load and store instructions. Additionally, any instructions that are dependent have to wait for the Load or store operation to complete even if disperse loads and stores do not operate on the same memory address. In order to maximize performance gains, researchers began experimenting with schemes to allow for out of order execution of loads and stores. In this paper we shall evaluate two such schemes: Store Sets, and Counting Dependency Predictors.</p><h2 id="1-2-The-Answer-Memory-Dependence-Prediction-Schemes"><a href="#1-2-The-Answer-Memory-Dependence-Prediction-Schemes" class="headerlink" title="1.2 The Answer: Memory Dependence Prediction Schemes"></a>1.2 The Answer: Memory Dependence Prediction Schemes</h2><p>When issuing a load out of program order, it is assumed that the load does not share an address with (i.e. depend upon) any stores which it has overtaken. Therefore, to issue loads out of program order while target addresses are unavailable, the processor requires Memory Dependence Prediction (MDP). This is very similar to Branch Prediction in that the processor guesses on a decision, detects a mishap, recovers state, and learns to avoid the same mistake on future encounters.</p><p>The two baseline (i.e. corner-cases) MPD schemes are No Speculation and Naive Speculation. Under the terms of No Speculation,  no ready loads will queue unless there are no non-ready stores behind it. Under the terms of Naive Speculation, loads will queue as soon as they are ready regardless of the number of non-ready loads behind it. Figure 2 illustrates the concepts of these two schemes. No Speculation and Naive Speculation represent the most conservative and the most aggressive MDP schemes, respectively.</p><p>Under the terms of the Store Sets algorithms, the processor incrementally logs the PCs of stores upon which loads have historically depended to determine the earliest point in time at which a given load may issue. As conflicting stores are first encountered (detected by Memory Order Violations), their PCs are added to the Store Set to improve future performance. Figure 3 shows illustrates this concept.</p><p>Today, distributed systems within which centralized fetch and execution streams are  infeasible pose a complication for MDP schemes such as Store Sets. To accommodate distributed systems for which memory dependence predictors do not have global knowledge stores at the full program level, the Counting Dependence Predictor (CDP) scheme predicts the number of stores (not specific PCs) which a load must wait for before it is issued. Moreover, the CDP can default the behavior of a given load to No Speculation (conservative) or Naive Speculation (aggressive) depending on how well it performs at run time. A state machine shown in Figure 4 prescribes the behavior of a given load and is designed to maximize overall performance without requisite maintenance of global store information.</p><h2 id="1-3-The-Purpose-of-this-Project"><a href="#1-3-The-Purpose-of-this-Project" class="headerlink" title="1.3 The Purpose of this Project"></a>1.3 The Purpose of this Project</h2><p>The purpose of this project was to extend the SimpleScalar’s sim-outorder simulator to investigate the effectiveness of Store Sets and CDP as MDP schemes. This required familiarization with the SimpleScalar/sim-outorder source code as well as with the selected MDP schemes. Practical feasibility (e.g. memory/power economy) was not a concern of this simulation-driven project, and so the presented implementations represent idealized  behavior with unrestricted architectural resources.</p><h1 id="2-0-Methods-amp-Materials"><a href="#2-0-Methods-amp-Materials" class="headerlink" title="2.0 Methods &amp; Materials"></a>2.0 Methods &amp; Materials</h1><h2 id="2-1-Overview-of-the-SimpleScalar-Out-of-Order-Simulator"><a href="#2-1-Overview-of-the-SimpleScalar-Out-of-Order-Simulator" class="headerlink" title="2.1    Overview of the SimpleScalar Out-of-Order Simulator"></a>2.1    Overview of the SimpleScalar Out-of-Order Simulator</h2><p>This project utilized the SimpleScalar Toolset to design/evaluate MDP schemes. The SimpleScalar toolset is divided into modules which are applicable to different types/levels of architectural analysis. Because this project was investigating a type of dynamic scheduling, the sim-outorder module was used. Conveniently, the sim-outorder software is solely confined to the file,simoutorder.c. Sim-outorder centers around the Register-Update-Unit(RUU) and Load-Store-Queue (LSQ) which allow instructions to issue/execute out of order but retire in order. Figure 1 illustrates the pipeline of sim-outorder. The RUU and LSQ are themselves simply arrays of the RUU_Station type, which is container for status information of in-flight instructions.</p><img src="/2017/09/15/Investigation-of-Memory-Dependence-Strategies/image4.png" class=""><p>Figure 1: Pipeline for sim-outorder with Memory Dependence Management Highlighted</p><h3 id="2-1-1-Memory-Dependence-Management-with-Load-Store-Queue-Refresh"><a href="#2-1-1-Memory-Dependence-Management-with-Load-Store-Queue-Refresh" class="headerlink" title="2.1.1 Memory Dependence Management with Load-Store-Queue Refresh"></a>2.1.1 Memory Dependence Management with Load-Store-Queue Refresh</h3><p>Memory operations are split into two separate instructions: the addition to compute the effective address  and the memory operations itself. The Load-Store-Queue Refresh function (lsq_refresh()), indicated in Figure 1, is an array of RUU_Stations of exclusively loads and stores. It’s functionality is to facilitate memory dependence checking and safe issuing of loads (stores are issued in ruu_issue()). Therefore, lsq_refresh() represented the entry point for most of the software developed for this project. In fact, seach MDP scheme implemented in this project is represented entirely by a variant of lsq_refresh() which is selectively called in it’s stead (See Section 2.3 for details).</p><p>By default,lsq_refresh() stalls any ready load if there exists an earlier store with an unresolved address in the LSQ. If however, the address is ready but the operands are not, lsq_refresh() will track the the store’s effective address and stall any ready load only if their addresses match. As will be shown next, this is a relaxed form of No Speculation combined with a rudimentary form of memory dependence checking which Store Sets extends across multiple clock cycles.</p><h2 id="2-2-Overview-of-the-Performance-Metrics"><a href="#2-2-Overview-of-the-Performance-Metrics" class="headerlink" title="2.2 Overview of the Performance Metrics"></a>2.2 Overview of the Performance Metrics</span></h2><p>The three metrics by which an MDP scheme is evaluated are (1) the Number of Memory Violations, the (2) Number of False Dependencies which have occurred during a program’s execution and the average (3) Instructions Per Cycle.</p><p>Memory Order Violation program error in which an out-of-order load loads a value before a prior store with a matching effective address completes storing its value to that address. This requires flushing the pipeline and recovering the processor to the state at the point of the offending load.</p><p>False Dependency program slow-down in which a ready load is stalled due to the detection of a prior unready store which does not have a matching effective address. This results in wasted clock cycles which reduces program execution speed.</p><p>Instructions Per Cycle (IPC) The average number of instructions which are retired per cycle. In multiple-issue processors like SimpleScalar, this can easily rise above 1.</p><h2 id="2-3-Implementation-of-the-MDP-Schemes-and-Metrics-Acquisition"><a href="#2-3-Implementation-of-the-MDP-Schemes-and-Metrics-Acquisition" class="headerlink" title="2.3    Implementation of the  MDP Schemes and Metrics Acquisition"></a>2.3    Implementation of the  MDP Schemes and Metrics Acquisition</h2><p>Implementing the MDP schemes primarily involved altering the actions taken during lsq_refresh(). Specifically, what to do in the event of a detected unready store and ready load. By default, simoutorder does not risk the possibility of Memory Order Violations. Moreover, the functionality to track the number of False Dependencies did not exist. Therefore, this project also involved developing code detect/track the events of Memory Order Violations and False Dependencies, which can be found in check_mem_violation() and countNumFalseDependencies(), respectively.</p><img src="/2017/09/15/Investigation-of-Memory-Dependence-Strategies/image8.png" class=""><img src="/2017/09/15/Investigation-of-Memory-Dependence-Strategies/image3.png" class=""><p>Figure 2 : Logic for Memory Dependence Algorithms</p><table><thead><tr><th>MDP Scheme</th><th>Memory Order Violations</th><th>False Dependencies</th><th>Project Function Name</th><th>CLI</th></tr></thead><tbody><tr><td>Default</td><td>None</td><td>Many</td><td>lsq_refresh()</td><td>0</td></tr><tr><td>No Speculation</td><td>None</td><td>Many</td><td>lsq_refresh_NoSpeculation()</td><td>1</td></tr><tr><td>Naive Speculation</td><td>Many</td><td>None</td><td>lsq_refresh_NaiveSpeculation()</td><td>2</td></tr><tr><td>Store Sets</td><td>Few</td><td>Few</td><td>lsq_refresh_InfStoreSets()</td><td>3</td></tr><tr><td>CDP</td><td>Few</td><td>Few</td><td>lsq_refresh_CountingDependencePredictor()</td><td>4</td></tr></tbody></table><p>Table 1: Expected relative behavior of algorithms</p><h3 id="2-3-1-No-Speculation-Conservative"><a href="#2-3-1-No-Speculation-Conservative" class="headerlink" title="2.3.1 No Speculation (Conservative)"></a>2.3.1 No Speculation (Conservative)</h3><p>For an algorithm which performs no speculation, the load instructions are dispatched to the memory system only when the addresses of all previous stores are known and the operands of those stores are ready. This configuration successfully avoids memory dependence violations entirely by ensuring memory instructions are issued in program order, but provides no prevention against false memory dependencies (see Table 1). As such, this conservative algorithm served as the baseline memory dependence management scheme against which subsequently implemented prediction schemes were compared for maximum false dependencies.</p><h3 id="2-3-2-Naive-Speculation-Aggressive"><a href="#2-3-2-Naive-Speculation-Aggressive" class="headerlink" title="2.3.2 Naive Speculation (Aggressive)"></a>2.3.2 Naive Speculation (Aggressive)</h3><p>The naive prediction algorithm assumes  no memory dependencies among store/load instructions. All load and store instructions are issued as soon as possible. This configuration is the opposite of no speculation in that no false dependencies occur, but maximum amount of memory violations are incurred. As such, this aggressive algorithm served as the baseline MDP scheme against which subsequently implemented MDP schemes were compared for maximum memory violations. Functionality to flush the pipeline when a memory violation occurs was not implemented in this simulation due to time constraints.</p><p>###2.3.3 Infinite Store Sets<br>The Store Sets algorithm predicts future memory violations based on their previous occurrences. Each load is initialized to behave according to Naive Speculation, in that it assumes it can issue as soon as it is able to. Upon detection of a memory order violation, the conflicted store and load relationship is saved into a table for future reference. This table is known as a Store Set. During a queue refresh, each ready load’s Store Set is searched for a match (i.e. conflict) with any unready store currently behind it. If a conflict is found, the load is stalled until the matching store is no longer on the  LSQ. Because no limits are imposed upon (1) the number of stores a load’s store set can contain, or (2) the number of store sets within which a unique store PC can exist, this implementation is considered to be an Infinite Store Set. These limits do exist in practical implementations which were not considered in this project. Figure 2 illustrates the simplified Infinite Store Sets concept implemented in this project.  For the project implementation, the Store Set Index is a C struct and the Store Set itself is simply a C array of addresses.</p><img src="/2017/09/15/Investigation-of-Memory-Dependence-Strategies/image11.png" class=""><p>Figure 3: Infinite Store Sets</p><h3 id="2-3-4-Counting-Dependence-Prediction"><a href="#2-3-4-Counting-Dependence-Prediction" class="headerlink" title="2.3.4 Counting Dependence Prediction"></a>2.3.4 Counting Dependence Prediction</h3><p>The counting dependence prediction algorithm uses a state machine for each unique load to determine the correct course of action. Unlike the Store Sets algorithm, the CDP algorithm does not maintain a record of specific Store PCs. Rather, it logs the number of stores which a load must wait for after being ready. This layer of detachment makes CDP an attractive MDP scheme for distributed systems within which globally broadcasted information may not be feasible.Similar to the store set algorithm, each load is initialized to behave according to Naive Speculation (i.e.Aggressive 00 ). As soon as a Memory Order Violation is detected, the state changes to No Speculation (i.e. Conservative.</p><p>Figure 4: Counting Dependence Predictor State Machine Diagram</p><p>As long as there is determined to be &gt;1 prior stores upon which this load depends (i.e. a Match ), the load will remain Conservative. As soon as there is determined to be 0 or 1 matching stores, the state will change to One-Store and volley between 01 or 11, respectively. If at any time, however, a Memory Order Violation is detected, the load’s CDP state will return to Conservative.  Figure 2 illustrates the CDP concept implemented in this project. For the project implementation, CDP Index is a C struct and the CDP state itself is simply a C enum comprising of the four aforementioned states.</p><h3 id="2-3-5-Memory-Order-Violation-and-False-Dependency-Detection"><a href="#2-3-5-Memory-Order-Violation-and-False-Dependency-Detection" class="headerlink" title="2.3.5 Memory Order Violation and False Dependency Detection"></a>2.3.5 Memory Order Violation and False Dependency Detection</h3><p>Because both Store Sets and CDP are initialized/updated by the event of Memory Order Violations, the project’s check_mem_violation() served three simultaneous purposes.</p><ol><li>Flags Memory Order Violations: issued loads the address of which conflicts with an unexecuted store(s).</li><li>Initializes/Updates the Store Set of the Offending Load</li><li>Initializes/Updates the CDP of the Offending Load</li></ol><p>Therefore, although check_mem_violation() is ostensibly merely metric tracker, it also completes the implementation of Store Set and CDP with state feedback The algorithm for Memory Order Violation detection is shown in Figure 5. What allows this algorithm to be effective is that it is called within RUU_Issue() specifically when a ready load is about to be executed. The False Dependency detection function ( countNumFalseDependencies() ), however, is purely a metric tracker and does not alter the state of ongoing Store Sets or CDP state structures. It is called immediately after the LSQ is refreshed. As shown in Figure 5, it simply counts the number of ready loads which come after an unready store. This is a definition of False Dependency which applies closely to No Speculation, but is loosely applicable to the other MDP schemes.</p><p>Figure 5: Logic for Memory order Violation Check and False Dependency Check</p><h2 id="2-4-Implementation-of-the-Simulations"><a href="#2-4-Implementation-of-the-Simulations" class="headerlink" title="2.4    Implementation of the Simulations"></a>2.4    Implementation of the Simulations</h2><p>The following test programs were run using the aforementioned MDP schemes.</p><table><thead><tr><th>Test Programs</th></tr></thead><tbody><tr><td>anagram</td></tr><tr><td>test-args</td></tr><tr><td>test-dirent</td></tr><tr><td>test-fmath</td></tr><tr><td>test-llong</td></tr><tr><td>test-lswlr</td></tr><tr><td>test-printf</td></tr></tbody></table><p>Table 2: Test programs used in the experiment</p><table><thead><tr><th>SimpleScalar Parameter</th><th>Val</th></tr></thead><tbody><tr><td>Instruction Fetch Queue Size (in inst/s)</td><td>4</td></tr><tr><td>Instruction Decode Width (insts/cycle)</td><td>4</td></tr><tr><td>Instruction Issue B/W (insts/cycle)</td><td>4</td></tr><tr><td>Instruction Commit B/W (insts/cycle)</td><td>4</td></tr><tr><td>Memory Access Bus Width (in bytes)</td><td>8</td></tr><tr><td>Register Update Unit Size</td><td>8</td></tr><tr><td>Load/Store Queue Size</td><td>4</td></tr></tbody></table><p>Table 3: Relevant Default Parameters for the Simulations</p><p>In order to specify the MDP scheme to run, additional code was written to selectively invoke a different lsq_reshresh_*() depending on the command line arguments as follows:</p><ul><li><p>./sim-outorder - ALGORITHM_TYPE 0 ./tests/bin/* // 0. Default SimpleScalar Behavior</p></li><li><p>./sim-outorder -ALGORITHM_TYPE 1 ./tests/bin/*  // 1. No Speculation</p></li><li><p>./sim-outorder -ALGORITHM_TYPE 2 ./tests/bin/*  // 2. Naive Speculation</p></li><li><p>./sim-outorder -ALGORITHM_TYPE 3 ./tests/bin/*  // 3. Store Sets</p></li><li><p>./sim-outorder -ALGORITHM_TYPE 4 ./tests/bin/*  // 4. Counting Dependence Predictor</p></li></ul><p>By invoking the -redir:sim command line argument simulation outputs were automatically logged to text files. These text files were generated for every combination of test program and MDP scheme, including Default. This resulted in different simulation output text files each of which contain the three principal performance metrics: Number of Memory Violations, Number of False Dependencies, and Average IPC. These results are shown in the next section.</p><h1 id="3-0-Results"><a href="#3-0-Results" class="headerlink" title="3.0 Results"></a>3.0 Results</h1><h2 id="3-1-Instructions-Per-Cycle-IPC"><a href="#3-1-Instructions-Per-Cycle-IPC" class="headerlink" title="3.1 Instructions Per Cycle (IPC)"></a>3.1 Instructions Per Cycle (IPC)</h2><p>The IPC is most direct measure of overall program performance. According to Figure 6, the various MDP schemes applied to the test data did not result in significant variation in IPC. Because the simulation parameters were fixed solely as described in Table 3, it is possible that these results would have shown greater variance if B/Ws were increased. Nonetheless, there was a consistent decrease in IPC for No Speculation which is by definition the most sluggish of all MDP schemes.</p><table><thead><tr><th>MDP Scheme \ Program</th><th>args</th><th>dirent</th><th>fmath</th><th>llong</th><th>lswlr</th><th>Math</th><th>printf</th></tr></thead><tbody><tr><td>Default</td><td>0.4638</td><td>0.3924</td><td>0.7803</td><td>0.6043</td><td>0.3613</td><td>0.9452</td><td>1.4645</td></tr><tr><td>No Spec</td><td>0.4635</td><td>0.3923</td><td>0.7778</td><td>0.6030</td><td>0.3611</td><td>0.9410</td><td>1.4531</td></tr><tr><td>Naive Spec</td><td>0.4641</td><td>0.3924</td><td>0.7803</td><td>0.6046</td><td>0.3613</td><td>0.9454</td><td>1.4658</td></tr><tr><td>Store Sets</td><td>0.4641</td><td>0.3924</td><td>0.7803</td><td>0.6045</td><td>0.3613</td><td>0.9453</td><td>1.4645</td></tr><tr><td>CDP</td><td>0.4610</td><td>0.3886</td><td>0.7773</td><td>0.3701</td><td>0.3588</td><td>0.8011</td><td>0.5214</td></tr></tbody></table><p>Table 4: Raw IPC Across Test Programs and MDP Schemes</p><img src="/2017/09/15/Investigation-of-Memory-Dependence-Strategies/image2.png" class=""><p>Figure 6: Plotted IPC Across Test Programs and MDP Schemes</p><h2 id="3-2-Number-of-Memory-Order-Violations"><a href="#3-2-Number-of-Memory-Order-Violations" class="headerlink" title="3.2 Number of Memory Order Violations"></a>3.2 Number of Memory Order Violations</h2><p>The number of Memory Order Violations generated by the simulations was largely consistent with the initial hypothesis. This is in that the Default, and No Speculation MDP schemes consistently resulted in zero Memory Order Violations. This verifies the project’s implementation of the check_mem_violation() function. By design, the Store Sets and CDP algorithm are intended to incur a few number of Memory Order Violations while affording an enhanced IPC. Because the results of the previous section indicated no IPC enhancements, sadly, we merely have only the predicted Memory Order Violation incursion.</p><table><thead><tr><th>MDP Scheme \ Program</th><th>args</th><th>dirent</th><th>fmath</th><th>llong</th><th>lswlr</th><th>Math</th><th>printf</th></tr></thead><tbody><tr><td>Default</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>No Spec</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>Naive Spec</td><td>3</td><td>0</td><td>5</td><td>15</td><td>0</td><td>45</td><td>1745</td></tr><tr><td>Store Sets</td><td>3</td><td>0</td><td>5</td><td>6</td><td>0</td><td>17</td><td>26</td></tr><tr><td>CDP</td><td>2</td><td>0</td><td>4</td><td>2</td><td>0</td><td>8</td><td>3</td></tr></tbody></table><p>Table 5 : Memory Violation Count Across Test Programs and MDP Schemes</p><img src="/2017/09/15/Investigation-of-Memory-Dependence-Strategies/image1.png" class=""><p>Figure 7: Plotted Memory Violation Count Across Test Programs and MDP Schemes</p><h2 id="3-2-Number-of-False-Dependencies"><a href="#3-2-Number-of-False-Dependencies" class="headerlink" title="3.2 Number of False Dependencies"></a>3.2 Number of False Dependencies</h2><p>The number of False Dependencies generated by the simulations was also largely consistent with the initial hypothesis. This is in that the Naive Speculation consistently resulted in zero False Dependencies. In addition the No Speculation MDP scheme resulted in the largest number of False Dependencies. This verifies the project’s implementation of the countNumFalseDependencies() function as well as baseline MDP schemes. It is optimistic that the Store Sets and CDP schemes resulted in fewer False Dependencies than the Default and No Speculation. However, as there was no significant improvement in IPC, the overall value of these experimental MDP schemes is still undemonstrated.</p><table><thead><tr><th>MDP Scheme \ Program</th><th>args</th><th>dirent</th><th>fmath</th><th>llong</th><th>lswlr</th><th>Math</th><th>printf</th></tr></thead><tbody><tr><td>Default</td><td>3</td><td>0</td><td>88</td><td>55</td><td>0</td><td>158</td><td>3342</td></tr><tr><td>No Spec</td><td>436</td><td>261</td><td>1300</td><td>565</td><td>351</td><td>2124</td><td>35342</td></tr><tr><td>Naive Spec</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>Store Sets</td><td>0</td><td>0</td><td>3</td><td>17</td><td>0</td><td>52</td><td>3591</td></tr><tr><td>CDP</td><td>17</td><td>24</td><td>57</td><td>22</td><td>27</td><td>63</td><td>27</td></tr></tbody></table><p>Table 6: False Dependency Count Across Test Programs and MDP Schemes</p><img src="/2017/09/15/Investigation-of-Memory-Dependence-Strategies/image6.png" class=""><p>Figure 8: Plotted False Dependency Count Across Test Programs and MDP Schemes</p><h1 id="4-0-Discussion"><a href="#4-0-Discussion" class="headerlink" title="4.0 Discussion"></a>4.0 Discussion</h1><p>The most significant metric which justifies an algorithm’s utility is the IPC. Because these results did not demonstrate a significant enhancement of IPC for either of the two experimental MDP schemes (Store Sets and CDP), their implementations cannot be proclaimed entirely successful. However, there were several aspects of the results which did support the correctness of their implementations and their consistency with theory. For example:</p><p>As expected, the Default and No Speculation MDPs generated no Memory Order Violations and the Naive Speculation MDP many Memory Order Violations. As expected, the Default and No Speculation MDPs generated significant number of False Dependencies and the Naive Speculation MDP generated no False Dependencies. These facts verify the implementations of the baseline MDPs. For the experimental MDPs, as expected, the Store Sets and CDP did generate Memory Order Violations, which is the trigger event by which the Store Sets and CDPs are to be initialized in the first place. Furthermore, as expected, number of False Dependencies generated by Store Sets and CDP are fewer than those of Default, No Speculation, and Naive Speculation.</p><p>The various parameters which dictate the width of instructions queueing/decoding/issuing/committing etc. were fixed for all simulations at either 4 or 8 (See Table 3). Because MDP schemes are intended to yield greater dividends for higher bandwidth processors, it is possible that increasing these parameters would reveal inter-MDP scheme variation in IPC. A follow on study in which the parameters of Table 3 are modulated could demonstrate this. Nonetheless there are a few implementation features of Store Sets, CDP, and metric tracking which were either approximated here or entirely foregone.</p><p>For example, although the mechanism to detect Memory Order Violations was implemented, the mechanism to recover processor state to the point of the offending load was not. This mechanism would be entirely analogous to that of processor state recovery during branch mis-prediction. The reason no such MDP recovery mechanism existed at first is that the default implementation of SimpleScalar does not allow the possibility of Memory Order Violations at all (See Figure 1). What this should mean is that every Memory Order Violation encountered here caused a programmatic error. However, sim-outorder prints the expected output of each simulated program adjacent to the generated output. Throughout all 40 simulation runs, no differences were seen between the expected and generated outputs. Although the reason for this lack of discrepancy is unknown, it does raise the possibility that SimpleScalar was somehow detecting the Memory Order Violations and recovering processor state. If this is so, the additional clock cycles cost from recovery were already accounted for in the provided results. If not, the implementations provided here are certainly incomplete and represent optimistic IPCs in that the penalty clock cycles of MDP recovery were not accounted for.</p><p>One last consideration is that the provided implementations did not strive for minimal memory usage in anyway. For instance, the Store Sets and CDP here maintained a separate index for each load. In practice, much like with branch prediction, the CDP and Store Sets would use reduced table sizes for loads to hash into, and not necessarily track all loads across the entire program execution.</p><h1 id="5-0-Conclusion"><a href="#5-0-Conclusion" class="headerlink" title="5.0 Conclusion"></a>5.0 Conclusion</h1><p>Because the effective addresses of Loads and Stores cannot always be known at the issue stage, dynamic scheduling processors have traditionally defaulted them to in-order scheduling to avoid Memory Order Violations. To exploit more ILP and reduce False Dependencies, Memory Dependence Prediction (MDP) schemes have been developed. This project sought to demonstrate the performance enhancement capabilities of two such MDP schemes, Store Sets and Counting Dependence Predictor (CDP), within the SimpleScalar simulation framework. SimpleScalar is an industry standard simulator and has been independently verified. Carrying out this project required the team’s thorough familiarization with the MDP scheme concepts as well as the SimpleScalar source code.</p><p>The project’s developed source code was peer reviewed by the members of the group and was submitted for further investigation.  The project’s developed source code was submitted with built in functionality to toggle between four different MDP schemes (plus Default); two baseline, and two experimental. The two baseline MDPs, No Speculation and Naive Speculation, successfully demonstrated the predicted behavior of maximizing False Dependencies and Memory Order Violations, respectively. Moreover, the Store Sets and CDP implementations demonstrated an expected moderate incurrence of Memory Order Violations and False Dependencies. However, the Store Sets and CDP did not demonstrate a significant enhancement of IPC; one of the primary benchmarks of an MDP scheme’s utility.</p><p>Possible explanations for this result include improper input parameter settings detailed in Table 3. Because MDPs are intended for wide-issue processors, it is possible that these particular set of parameters were insufficient to reveal the intended benefits. Moreover, CDP is necessarily a more handicapped version of Store Sets that would only be functionally relevant if SimpleScalar were implemented as a distributed system.</p><p>This project enabled the group members to not only learn about but take on Computer Architecture research through the power of modelling &amp; simulation. Carrying out this project allowed us to combine architectural theory with hands-on quantitative performance analysis. Doing so allowed us to act in the capacity of, not only students, but designers.</p><h1 id="6-0-References"><a href="#6-0-References" class="headerlink" title="6.0 References"></a>6.0 References</h1><p>[1] G. Z. Chrysos and J. S. Emer. Memory dependence prediction using store sets. In Proceedings of the 25th Annual International Symposium on Computer Architecture, ISCA ‘98, pages 142{153, Washington, DC, USA, 1998. IEEE Computer Society<br>[2] D. Burger, T. M. Austin. The SimpleScalar Tool Set, Version 2.0.</p><p>[3]F. Roesner, D. Burger, and S. W. Keckler. Counting dependence predictors. In Proceedings of the 35th Annual International Symposium on Computer Architecture  ISCA ‘08, pages 215{226, Washington, DC, USA, 2008. IEEE Computer Society.</p>]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2017/09/15/Investigation-of-Memory-Dependence-Strategies/image7.png&quot; class=&quot;&quot;&gt;

&lt;h2 id=&quot;Computer-Architecture&quot;&gt;&lt;a href=&quot;#Computer-Architecture&quot; class=&quot;headerlink&quot; title=&quot;Computer Architecture&quot;&gt;&lt;/a&gt;Computer Architecture&lt;/h2&gt;&lt;h2 id=&quot;Investigation-of-Memory-Dependence-Prediction-Strategies-with-SimpleScalar&quot;&gt;&lt;a href=&quot;#Investigation-of-Memory-Dependence-Prediction-Strategies-with-SimpleScalar&quot; class=&quot;headerlink&quot; title=&quot;Investigation of Memory Dependence Prediction Strategies with SimpleScalar&quot;&gt;&lt;/a&gt;Investigation of Memory Dependence Prediction Strategies with SimpleScalar&lt;/h2&gt;&lt;h3 id=&quot;Lorenzo-Allas-John-Grun-Sanandeesh-Kamat&quot;&gt;&lt;a href=&quot;#Lorenzo-Allas-John-Grun-Sanandeesh-Kamat&quot; class=&quot;headerlink&quot; title=&quot;Lorenzo Allas, John Grun, Sanandeesh Kamat&quot;&gt;&lt;/a&gt;Lorenzo Allas, John Grun, Sanandeesh Kamat&lt;/h3&gt;&lt;img src=&quot;/2017/09/15/Investigation-of-Memory-Dependence-Strategies/image5.png&quot; class=&quot;&quot;&gt;

&lt;img src=&quot;/2017/09/15/Investigation-of-Memory-Dependence-Strategies/image12.jpg&quot; class=&quot;&quot;&gt;

&lt;h1 id=&quot;0-0-Abstract&quot;&gt;&lt;a href=&quot;#0-0-Abstract&quot; class=&quot;headerlink&quot; title=&quot;0.0 Abstract&quot;&gt;&lt;/a&gt;0.0 Abstract&lt;/h1&gt;&lt;p&gt;A dynamically scheduled processor may default to in-order execution of Load/Store instructions to avoid Memory Order Violations. This is because, loads executed out of order may be dependent upon prior stores, the addresses of which were initially unknown. To overcome the potentially wasted clock cycles of conservatively stalled loads, known as False Dependencies, Memory Dependence Predictor (MDP) schemes have been developed. This paper demonstrates the implementation of two experimental MDP schemes, Store Sets and Counting Dependence Predictor (CDP) within the SimpleScalar framework. In addition, it demonstrates two baseline MDP schemes, No Speculation and Naive Speculation. The conceptual overview, the software implementation details, as well as quantitative simulation results are provided. The performance of these MDP schemes has been evaluated in terms of three metrics: the number of Memory Order Violations, the number of False Dependencies, and the average IPC. Although the results did not indicate a performance enhancement in terms of execution time, they do demonstrate expected behavior in terms of Memory Order Violations and False Dependencies. Possible implementation shortcomings, and future alterations are later proposed.&lt;/p&gt;
    
    </summary>
    
    
      <category term="Computing" scheme="http://questionableengineering.com/tags/Computing/"/>
    
      <category term="Research" scheme="http://questionableengineering.com/tags/Research/"/>
    
  </entry>
  
  <entry>
    <title>Nodejs 6 on Ubuntu 16.04 LTS</title>
    <link href="http://questionableengineering.com/2017/09/09/Nodejs-6-on-Ubuntu-16-04-LTS/"/>
    <id>http://questionableengineering.com/2017/09/09/Nodejs-6-on-Ubuntu-16-04-LTS/</id>
    <published>2017-09-10T00:52:48.000Z</published>
    <updated>2017-12-27T04:17:49.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Nodejs-6-on-Ubuntu-16-04-LTS"><a href="#Nodejs-6-on-Ubuntu-16-04-LTS" class="headerlink" title="Nodejs 6 on Ubuntu 16.04 LTS"></a>Nodejs 6 on Ubuntu 16.04 LTS</h3><p>ERROR : Buffer.alloc is not a function </p><span id="more"></span><p>Fix: upgrade nodejs to Version &gt; 5.1</p><pre><code>curl -s https://deb.nodesource.com/gpgkey/nodesource.gpg.key | sudo apt-key add -sudo sh -c &quot;echo deb https://deb.nodesource.com/node_6.x yakkety main \ &gt; /etc/apt/sources.list.d/nodesource.list&quot; sudo apt-get updatesudo apt-get install nodejs</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Nodejs-6-on-Ubuntu-16-04-LTS&quot;&gt;&lt;a href=&quot;#Nodejs-6-on-Ubuntu-16-04-LTS&quot; class=&quot;headerlink&quot; title=&quot;Nodejs 6 on Ubuntu 16.04 LTS&quot;&gt;&lt;/a&gt;Nodejs 6 on Ubuntu 16.04 LTS&lt;/h3&gt;&lt;p&gt;ERROR : Buffer.alloc is not a function &lt;/p&gt;
    
    </summary>
    
    
      <category term="Fixes" scheme="http://questionableengineering.com/tags/Fixes/"/>
    
      <category term="NodeJs" scheme="http://questionableengineering.com/tags/NodeJs/"/>
    
      <category term="Ubuntu" scheme="http://questionableengineering.com/tags/Ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>Analysis of the Kalman Filter Algorithm</title>
    <link href="http://questionableengineering.com/2017/07/07/Report/"/>
    <id>http://questionableengineering.com/2017/07/07/Report/</id>
    <published>2017-07-07T21:46:15.000Z</published>
    <updated>2023-09-04T23:05:28.409Z</updated>
    
    <content type="html"><![CDATA[<p><img src="image_0.png"></p><table><thead><tr><th><img src="image_1.png"></th><th><img src="image_2.jpg"></th></tr></thead></table><h1 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h1><p>The Kalman filter finds applications in extracting useful data from inherently noisy sources. One common application is smoothing sensor data. In order for most sensor data to be effectively employed in applications like control loops or navigation systems it must first be filtered in a manner that removes noise but, does not introduce an unacceptable amount of additional error or increases processing and memory load on the system. In this regard the Kalman filter excels. The Kalman filter can also be extended to combine data from multiple input sources to further reduce the error in a signal or sample. This property has many applications in the area of sensor fusion. Kalman filter sensor fusion is commonly used in robotic control systems. A common use case is autonomous vehicle navigation and control eg. Quadcopters or spacecraft. Additionally, the Kalman filter is often used in analog and digital signal processing. The Kalman filter algorithm enjoys implementations in both software and hardware. </p><span id="more"></span><h2 id="Describe-Algorithm-details"><a href="#Describe-Algorithm-details" class="headerlink" title="Describe Algorithm details"></a>Describe Algorithm details</h2><p>The Kalman filter algorithm uses multiple input signals samples, often periodically, to increase the overall estimation accuracy of the signal with noise removed. The Kalman filter has 5 sets of variables one must understand. The the first is the self-explanatory unfiltered input signal. It is important to state, the algorithm assumes that all input signals into the filter contain a certain amount of noise variance. The Kalman gain, which is recursively calculated from the variance of the input signal over many samples. The last state (Xk-1) of the system, which is a gain weighted sum of all previous input signal samples. The current state (Xk) , which is an estimate of the expected state of the system as calculated by a function that describes the system/signal. The output signal is a gain weighted sum of the value of the current input signal and the current state estimation of the system. The Kalman filter algorithm uses two main components, a predicative step and a update step. See Figure 1. </p><table><thead><tr><th><img src="image_3.png"></th><th><img src="image_4.png"></th></tr></thead><tbody><tr><td>Figure 1. Simplified process flow representation of input signal and estimation in kalman filter.</td><td></td></tr></tbody></table><p>In the predictive step the Kalman filter relies upon a function model of the system/signal in order to calculate the predicted current state (Xk) from the last state (Xk-1) and any relevant input signals. The system/signal predicted variance is also calculated in this step. </p><p>In the update step, the next estimated output signal is produced from a gain weighted sum of the estimated current state and the new input signal sample. In the case of a temperature sensor, the Kalman filter would produce a new estimated temperature for the output from the gain weighted sum of previous temperature samples and the new temperature sample. The gain is calculated based upon the variance observed between the predicted variance and the variance of the new sample. The filter is tuned to give a higher weight to samples with lower error. </p><h2 id="Explain-why-the-chosen-algorithms-are-employed-for-the-problem"><a href="#Explain-why-the-chosen-algorithms-are-employed-for-the-problem" class="headerlink" title="Explain why the chosen algorithms are employed for the problem."></a>Explain why the chosen algorithms are employed for the problem.</h2><p>The algorithm has found employment as a solution to many common engineering problems such as processing inputs into control systems and for fusing sensor data from multiple sources. The algorithm is popular as a solution to these problems due to its low memory and processing footprint, constant running time, and comparatively simple design as compared to other solutions. The Kalman filter reduces the amount of working memory required by encoding past history of the inputs into a single current state variable (Xk). This encoding reduces the amount of memory consumed by the algorithm as past information does not need to be retained. Additionally, the amount of data processing per signal sample is reduced as only the current state variable and new sample are processed. These reductions in processing and memory are advantages in resource constrained environments, such as embedded systems or hardware implementations. The Kalman filter algorithm also lends itself well to “real time” systems such as robotic control where a predictable delay and constant runtime is required.The Kalman filter algorithm has a O(1) processing complexity and a O(1) memory space complexity. The Kalman filter can also be extended to combine inputs from multiple sources to further reduce signal sample variance. This    property lends itself well to  applications employing sensor fusion such as inertial navigation units (INUs) </p><h2 id="Experimental-configuration-and-details"><a href="#Experimental-configuration-and-details" class="headerlink" title="Experimental configuration and details."></a>Experimental configuration and details.</h2><p>The experiment consists of a force sensitive resistor sensor sampled once every 100 mSec by an Arduino compatible microcontroller(ESP8266). The microcontroller sends the raw sensor samples to the computer over a serial connection. The computer then writes the raw samples to a file on the hard disk (Data.txt). Once a large number of samples have been collected, the raw samples are passed into the Kalman filter(KalmanFilterWrapper.exe).  KalmanFilterWrapper.exe produces two output files KALMAN_INPUT_VS_OUTPUT.csv and KALMAN_FILTER_RUNNING_TIME_VS_INPUT_SIZE.csv that contain the raw samples vs the Kalman filtered samples and the running time vs input size respectively.  Kalman filters will often have many sensor inputs , process time variant signals, and must account for control inputs. With the addition of more inputs a gain matrix must be maintained that relates each input to each other input in addition to the gain between current Xk and last state Xk-1. These factors quickly drive a simple algorithm into such a complex system that it is used routinely in PHD. thesi.  For these reasons, a simple implementation of the Kalman was chosen. Finally, a simpler implementation will clearly show the algorithm operation. The implemented Kalman filter is processing a single variable, static , time invariant signal(Voltage proportional to the weight of Expo marker) In this implementation, the function model of the system/signal is Current state = last state  I.e Xk = Xk-n. The test should clearly show noise in raw samples and the resulting filtered output of the Kalman filter.  </p><img src="/2017/07/07/Report/Test_setup.png" class=""><img src="/2017/07/07/Report/20170427_214518.jpg" class=""><p>Figure 2: Experimental setup to collect sensor data. EXPO marker used to provide static weight greater than baseline. </p><img src="/2017/07/07/Report/Kalman_sensor_collection_schematic.png" class=""><p>Figure 3. Schematic of the circuit used to collect data and send information the the computer.</p><h3 id="Source-code-and-related-information-to-reproduce-experiment"><a href="#Source-code-and-related-information-to-reproduce-experiment" class="headerlink" title="Source code and related information to reproduce experiment"></a>Source code and related information to reproduce experiment</h3><ul><li><p>Arduino code to collect samples:</p><p>  DataStructuresKalmanFilter.ino </p></li><li><p>Schematic of sensor collection:</p><p>  Kalman_sensor_collection_schematic.pdf</p></li><li><p>Kalman filter Source Code see:</p><p>  KalmanFilterWrapper.cpp – Wrapper to process data and produce output files</p><p>  ./KalmanFilter.cpp – Kalman filter implementation </p></li><li><p>Run make in project root to compile C++ source code.</p><p>  make</p></li><li><p>Exec KalmanFilterWrapper.exe to produce outfiles</p><p>  KALMAN_INPUT_VS_OUTPUT.csv</p><p>  KALMAN_FILTER_RUNNING_TIME_VS_INPUT_SIZE.csv</p></li></ul><p>All code can be found at <a href="https://github.com/JohnGrun/KalmanFilterPaper">https://github.com/JohnGrun/KalmanFilterPaper</a></p><h3 id="Sources-of-Variance-in-the-experiment"><a href="#Sources-of-Variance-in-the-experiment" class="headerlink" title="Sources of Variance in the experiment"></a>Sources of Variance in the experiment</h3><h4 id="Raw-measurement-sources-of-known-variance"><a href="#Raw-measurement-sources-of-known-variance" class="headerlink" title="Raw measurement sources of known variance"></a>Raw measurement sources of known variance</h4><p>The sensor employed(FSR406) has tolerance of 2% at constant temperature as called out in the data sheet Datasheets_FSR.pdf. At a supply voltage of 3.3v, 2% is ~0.066 Volts of error due to the FSR sensor.See references for link to data sheet. </p><p>The Esp8266 ADC has a resolution of 12 bits or 4096 divisions. With a  Vcc = 3.3V; 4096 = 3.3 Volts, 0 = 0 Volts. A change of 1 in a measurement corresponds to 3.3/4096 = 0.00080566406 Volts. Compared the 0.066 Volts of error introduced by the FSR sensor the ADC resolution is not seen to be significant and, can thus be neglected in calculations.</p><h4 id="Running-time-sources-of-known-variance"><a href="#Running-time-sources-of-known-variance" class="headerlink" title="Running time sources of known variance"></a>Running time sources of known variance</h4><p>The running time of the algorithm may be influenced by external factors such as file system assess, resource allocations, paging, or process scheduling. To compensate for the  aforementioned sources of external variances many samples have to be taken.</p><h2 id="Results-and-Analysis"><a href="#Results-and-Analysis" class="headerlink" title="Results and Analysis"></a>Results and Analysis</h2><img src="/2017/07/07/Report/KALMAN_vs_Raw_graph.png" class=""><p>Figure 4. Sensor samples of proportional voltage to weight of EXPO marker. Raw samples from FSR sensor (Blue). Kalman filtered data of samples (Orange).</p><p>As can be seen in Figure 4, the raw samples contain a large amount of noise. The standard deviation of the raw samples was 1478.01. A static, time invariant signal( Voltage proportional to the weight of Expo marker) with such a high standard deviation is unusable in real world applications. Once the signal is processed by the Kalman filter, and significant time has passed, the signal become far less variable. The standard deviation of Kalman filtered signal was 98.07, a full order of magnitude less than the raw input signal. Additionally, the filtered signal reached a stable output with low variance as would be expected with a static input signal (Voltage proportional to the weight of Expo marker). </p><img src="/2017/07/07/Report/Running_Time_of_Kalman_Filter_vs_input_size.png" class=""><p>Figure 5. Running Time vs Input size. Running time (Blue) of each call to the Kalman filter algorithm using same data in Figure 4. </p><p>The second graph Figure 5. depicts the running time of the Kalman filter vs the number of samples processed. As expected, the running time is O(1). The Kalman filter only processes one measurement at a time. The output estimation is a weighted sum the past state( all previous samples) and the current measurement state and is updated once per function call. Only for 2 data points out of 5121 samples did the running time change significantly. These 2 data points are likely due to other factors not related to the Kalman filter, such as process scheduling or file system assesses on the host computer.  </p><h2 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h2><p> As can be seen from the results of the experiments the Kalman filter algorithm manages to clean up a noisy signal while running in constant time. There are two limitations of the Kalman filter algorithm. The algorithm requires a finite amount of startup time to reach a output that is representative of the filtered signal see Figure 4. In practice, as long as this startup time can be tolerated, a valid output signal can be extracted. The other limitation is that the Kalman filter algorithm requires knowledge of the process. This is manifested in the prediction stage, where the value of Xk is based upon an equation describing how the system/signal will change over time. E.g. Xk = F(Xkn-1,input1, input2). This makes it difficult to use a Kalman filter algorithm as general case filter, or where the input signal does not have a known function describing its behavior. If one can tolerate these minor shortcomings the Kalman filter algorithm is an excellent choice to clean up noisy input signals with minimal memory and processing overhead.       </p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>The Extended Kalman Filter: An Interactive Tutorial for Non-Experts. (2017, April 28). Retrieved April 28, 2017, from <a href="https://home.wlu.edu/~levys/kalman_tutorial/kalman_01.html">https://home.wlu.edu/~levys/kalman_tutorial/kalman_01.html</a></p><p>Kelly, A. (2006, May 24). A 3D State Space Formulation of a Navigation Kalman Filter for Autonomous Vehicles. Retrieved April 3, 2017, from <a href="http://www.frc.ri.cmu.edu/~alonzo/pubs/reports/kalman_V2.pdf">http://www.frc.ri.cmu.edu/~alonzo/pubs/reports/kalman_V2.pdf</a></p><p>Welch, G., &amp; Bishop, G. (2001). An Introduction to the Kalman Filter. Retrieved April 3, 2017, from <a href="http://www.cs.unc.edu/~tracker/media/pdf/SIGGRAPH2001_CoursePack_08.pdf">http://www.cs.unc.edu/~tracker/media/pdf/SIGGRAPH2001_CoursePack_08.pdf</a></p><p>Wikipedia. (2017, April 28). Variance. Retrieved April 3, 2017, from <a href="https://en.wikipedia.org/wiki/Variance">https://en.wikipedia.org/wiki/Variance</a></p><p>Interlink Electronics. (2017, April 4). FS R ® 400 Series Data Sheet. Retrieved April 4, 2017, from <a href="https://www.interlinkelectronics.com/datasheets/Datasheet_FSR.pdf">https://www.interlinkelectronics.com/datasheets/Datasheet_FSR.pdf</a></p><p>Kohanbash, Y. (2014, January 30). Kalman Filtering – A Practical Implementation Guide (with code!). Retrieved April 29, 2017, from <a href="http://robotsforroboticists.com/kalman-filtering/">http://robotsforroboticists.com/kalman-filtering/</a></p><p>Wikipedia. (2017, April 06). Kalman filter. Retrieved April 29, 2017, from <a href="https://en.wikipedia.org/wiki/Kalman_filter">https://en.wikipedia.org/wiki/Kalman_filter</a> </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;image_0.png&quot;&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;img src=&quot;image_1.png&quot;&gt;&lt;/th&gt;
&lt;th&gt;&lt;img src=&quot;image_2.jpg&quot;&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h1 id=&quot;Motivation&quot;&gt;&lt;a href=&quot;#Motivation&quot; class=&quot;headerlink&quot; title=&quot;Motivation&quot;&gt;&lt;/a&gt;Motivation&lt;/h1&gt;&lt;p&gt;The Kalman filter finds applications in extracting useful data from inherently noisy sources. One common application is smoothing sensor data. In order for most sensor data to be effectively employed in applications like control loops or navigation systems it must first be filtered in a manner that removes noise but, does not introduce an unacceptable amount of additional error or increases processing and memory load on the system. In this regard the Kalman filter excels. The Kalman filter can also be extended to combine data from multiple input sources to further reduce the error in a signal or sample. This property has many applications in the area of sensor fusion. Kalman filter sensor fusion is commonly used in robotic control systems. A common use case is autonomous vehicle navigation and control eg. Quadcopters or spacecraft. Additionally, the Kalman filter is often used in analog and digital signal processing. The Kalman filter algorithm enjoys implementations in both software and hardware. &lt;/p&gt;
    
    </summary>
    
    
      <category term="Computing" scheme="http://questionableengineering.com/tags/Computing/"/>
    
      <category term="Research" scheme="http://questionableengineering.com/tags/Research/"/>
    
      <category term="Kalman" scheme="http://questionableengineering.com/tags/Kalman/"/>
    
      <category term="C++" scheme="http://questionableengineering.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>CNC Conversion Mechanical</title>
    <link href="http://questionableengineering.com/2014/10/29/CNC-Conversion-MARS/"/>
    <id>http://questionableengineering.com/2014/10/29/CNC-Conversion-MARS/</id>
    <published>2014-10-29T18:49:34.000Z</published>
    <updated>2023-09-03T15:05:51.546Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Mini-Mill"><a href="#Mini-Mill" class="headerlink" title="Mini Mill"></a>Mini Mill</h1><p><a href="https://littlemachineshop.com/products/product_view.php?ProductID=3990&category=1387807683">Hi Torque Mini Mill.</a></p><img src="/2014/10/29/CNC-Conversion-MARS/3990.480.jpg" class=""><h1 id="Unboxing-the-kit"><a href="#Unboxing-the-kit" class="headerlink" title="Unboxing the kit."></a>Unboxing the kit.</h1><p>CNC FUSION KIT</p><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20140110_223518.jpg" class=""><p>Unfortunately, this company is no longer around. Thankfully, there are other kits available to perform this conversion.</p><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20141029_183154.jpg" class=""><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20141029_183428.jpg" class=""><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20141029_183444.jpg" class=""><ul><li>Solid Column upgrade<img src="/2014/10/29/CNC-Conversion-MARS/IMG_20141029_183226.jpg" class="">The original hi torque mini mill from Little Machine Shop had a gimmicky tilting column. While it was nice to be able to tilt the mill head it was impossible to tram the mill. This solid column is complete replacement for the tilting column. <h1 id="Disassembly"><a href="#Disassembly" class="headerlink" title="Disassembly"></a>Disassembly</h1></li></ul><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20141029_183021.jpg" class=""><p>X/y stage separated from the rest of the mill. The tilting column version only required removing one large bolt on the back of the mill. </p><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20141029_184618.jpg" class=""><p>Tilting column with z axis </p><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20141102_223439.jpg" class=""><p>Front of the tilting column with the mill head removed.</p><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20141102_223448.jpg" class=""><h1 id="X-and-Y-axis"><a href="#X-and-Y-axis" class="headerlink" title="X and Y axis"></a>X and Y axis</h1><ul><li><p>The ballscrew is slightly too long. So we will have to do a little metal removal. </p><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20141105_140253.jpg" class=""></li><li><p>The ballscrew hits the other side of the casting</p><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20141105_140302.jpg" class=""><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20141105_140306.jpg" class=""></li><li><p>Grinding out a small pocket to fit the ballscrew end. This was done with a rotary tool and a mini end mill. </p><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20141106_161809.jpg" class=""></li></ul><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20141106_161820.jpg" class=""><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20141106_181515.jpg" class=""><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20141106_202831.jpg" class=""><p>Mounting the x ballscrew to the bottom of the x. I believe this mounted using the existing tapped holes.</p><ul><li>Assembled X and Y table<img src="/2014/10/29/CNC-Conversion-MARS/20141211_200438.jpg" class=""></li></ul><h1 id="Z-axis"><a href="#Z-axis" class="headerlink" title="Z axis"></a>Z axis</h1><ul><li>Tapping the mounting holes for the z axis ballscrew mount<img src="/2014/10/29/CNC-Conversion-MARS/IMG_20141103_201724.jpg" class="">The z axis ballscrew is positioned off to the side of the main column. We have to attach a metal plate to the top of the column in order to mount the ballscrew. This requires locating the mounting plate. Using center taps to locate the mounting holes. Drilling the mounting holes. Tapping the mounting holes.<img src="/2014/10/29/CNC-Conversion-MARS/IMG_20141103_201732.jpg" class=""></li></ul><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20141204_182959.jpg" class=""><p>Z axis ballscrew mounted on the main column. Metal mounting plate attached to the top of the column. Ballscrew nut attached to the mill head via two mounting holes. </p><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20141204_183006.jpg" class=""><p>Another view of the z axis. </p><h1 id="Electronics"><a href="#Electronics" class="headerlink" title="Electronics"></a>Electronics</h1><h2 id="Controller"><a href="#Controller" class="headerlink" title="Controller"></a>Controller</h2><ul><li>Beagle Bone Black<img src="/2014/10/29/CNC-Conversion-MARS/Beagle_Bone_Black.jpg" class=""></li></ul><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20141029_184635.jpg" class=""><h2 id="Interface-card"><a href="#Interface-card" class="headerlink" title="Interface card"></a>Interface card</h2><p>C10- PARALLEL PORT INTERFACE CARD</p><h2 id="Motor-Controllers"><a href="#Motor-Controllers" class="headerlink" title="Motor Controllers"></a>Motor Controllers</h2><p>M880A</p><a href="/2014/10/29/CNC-Conversion-MARS/M880Am.pdf" title="M880Am.pdf">M880Am.pdf</a><h2 id="Control-Board"><a href="#Control-Board" class="headerlink" title="Control Board"></a>Control Board</h2><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20141124_054550.jpg" class=""><img src="/2014/10/29/CNC-Conversion-MARS/20150325_235954.jpg" class=""><p>View of the inside of the electronics enclosure. This is a NEMA 4 enclosure the minimum you need when dealing with possible over spray. </p><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20141029_184023.jpg" class=""><p>Electronics mounted in the enclosure. Top left parallel port interface card mounted on standoffs above the beagle bone black. Top right the CNC electronics from the original hi torque mini mill. Left middle - A DC to DC power supply to produce 5v for all 5 volt components including the beagle bone black and parallel port card. Center middle - Stepper motor controllers. Right middle 36 v power supply. Bottom Din rail mounted terminal strip. </p><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20141029_184056.jpg" class=""><h2 id="Spindle-Control"><a href="#Spindle-Control" class="headerlink" title="Spindle Control"></a>Spindle Control</h2><p>The original mill only had a simple pot to turn for spindle control. This will not work for a CNC that needs to vary the spindle control throughout a job. To correct this short coming we’re going to replace the original spindle control with a 0-10 volt control. This will allow the beagle bone black him costume the books speed and direction via then parallel port adapter.</p><p><a href="https://littlemachineshop.com/products/product_view.php?ProductID=4213">CNC Spindle Control Upgrade Kit, Mini Lathe and Mini Mill</a></p><a href="/2014/10/29/CNC-Conversion-MARS/4213CNCSpindleControlUpgradeKit.pdf" title="4213CNCSpindleControlUpgradeKit.pdf">4213CNCSpindleControlUpgradeKit.pdf</a><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20111121_235136.jpg" class=""><img src="/2014/10/29/CNC-Conversion-MARS/20150418_100057.jpg" class=""><p>Mounting the spindle control </p><img src="/2014/10/29/CNC-Conversion-MARS/20141208_192455.jpg" class=""><p>Wiring the spindle control to the CNC controller board. This is a direct replacement available for this mill from Little Machine Shop.</p><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20111121_235504.jpg" class=""><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20111121_235510.jpg" class=""><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20111121_235456.jpg" class=""><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20111121_235211.jpg" class=""><img src="/2014/10/29/CNC-Conversion-MARS/IMG_20111121_235147.jpg" class=""><p>Cnc control board as seen mounted on the enclosure. </p><h1 id="Electronics-Enclosure"><a href="#Electronics-Enclosure" class="headerlink" title="Electronics Enclosure"></a>Electronics Enclosure</h1><img src="/2014/10/29/CNC-Conversion-MARS/20141211_200408.jpg" class=""><p>Mounting the read of the main column </p><img src="/2014/10/29/CNC-Conversion-MARS/20141211_200426.jpg" class=""><img src="/2014/10/29/CNC-Conversion-MARS/20150425_234534.jpg" class=""><p>View of the connections to the motors and end stops. I also added HDMI, USB, and Ethernet pass throughs to allow connection to the beagle bone. </p><h1 id="Complete"><a href="#Complete" class="headerlink" title="Complete"></a>Complete</h1><img src="/2014/10/29/CNC-Conversion-MARS/20150326_212850.jpg" class=""><p>View of machine kit (Linux cnc) running on the beagle bone black.</p><img src="/2014/10/29/CNC-Conversion-MARS/20150326_212820.jpg" class=""><p>Completed CNC machine </p><img src="/2014/10/29/CNC-Conversion-MARS/20150427_175709.jpg" class=""><p>Cnc up and running with monitor mounted on side. </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Mini-Mill&quot;&gt;&lt;a href=&quot;#Mini-Mill&quot; class=&quot;headerlink&quot; title=&quot;Mini Mill&quot;&gt;&lt;/a&gt;Mini Mill&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://littlemachineshop.com/pro
      
    
    </summary>
    
    
      <category term="CNC" scheme="http://questionableengineering.com/tags/CNC/"/>
    
  </entry>
  
  <entry>
    <title>Large CNC</title>
    <link href="http://questionableengineering.com/2011/12/04/Large-CNC/"/>
    <id>http://questionableengineering.com/2011/12/04/Large-CNC/</id>
    <published>2011-12-04T19:40:20.000Z</published>
    <updated>2023-09-02T20:36:43.972Z</updated>
    
    <content type="html"><![CDATA[<img src="/2011/12/04/Large-CNC/IMG_20111204_200636.jpg" class=""><img src="/2011/12/04/Large-CNC/IMG_20111204_200644.jpg" class=""><img src="/2011/12/04/Large-CNC/IMG_20111204_231234.jpg" class=""><img src="/2011/12/04/Large-CNC/IMG_20111204_232254.jpg" class=""><img src="/2011/12/04/Large-CNC/IMG_20111204_232417.jpg" class=""><img src="/2011/12/04/Large-CNC/IMG_20111204_232431.jpg" class=""><img src="/2011/12/04/Large-CNC/IMG_20111212_233628.jpg" class=""><img src="/2011/12/04/Large-CNC/IMG_20111214_235816.jpg" class=""><img src="/2011/12/04/Large-CNC/IMG_20111214_235831.jpg" class=""><img src="/2011/12/04/Large-CNC/IMG_20111214_235904.jpg" class=""><img src="/2011/12/04/Large-CNC/IMG_20111214_235934.jpg" class="">]]></content>
    
    <summary type="html">
    
      
      
        &lt;img src=&quot;/2011/12/04/Large-CNC/IMG_20111204_200636.jpg&quot; class=&quot;&quot;&gt;

&lt;img src=&quot;/2011/12/04/Large-CNC/IMG_20111204_200644.jpg&quot; class=&quot;&quot;&gt;

&lt;img
      
    
    </summary>
    
    
      <category term="CNC" scheme="http://questionableengineering.com/tags/CNC/"/>
    
  </entry>
  
</feed>
